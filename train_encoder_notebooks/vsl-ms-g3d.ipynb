{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.12"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":14603584,"sourceType":"datasetVersion","datasetId":9273717}],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%pip install -q faiss-cpu mediapipe==0.10.14","metadata":{"execution":{"iopub.status.busy":"2026-01-25T14:37:38.048665Z","iopub.execute_input":"2026-01-25T14:37:38.048985Z","iopub.status.idle":"2026-01-25T14:37:41.130131Z","shell.execute_reply.started":"2026-01-25T14:37:38.048941Z","shell.execute_reply":"2026-01-25T14:37:41.129393Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Note: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\", category=RuntimeWarning)","metadata":{"execution":{"iopub.status.busy":"2026-01-25T14:37:41.131876Z","iopub.execute_input":"2026-01-25T14:37:41.132127Z","iopub.status.idle":"2026-01-25T14:37:41.136091Z","shell.execute_reply.started":"2026-01-25T14:37:41.132104Z","shell.execute_reply":"2026-01-25T14:37:41.135394Z"},"trusted":true},"outputs":[],"execution_count":4},{"cell_type":"code","source":"import os\nimport numpy as np\nimport random\nimport json\nfrom torch.utils.data import Dataset, Sampler\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.cuda.amp import GradScaler, autocast\nfrom tqdm import tqdm\nimport time\nimport faiss\nimport csv\nimport mediapipe as mp","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2026-01-25T14:37:41.136966Z","iopub.execute_input":"2026-01-25T14:37:41.137226Z","iopub.status.idle":"2026-01-25T14:37:58.900711Z","shell.execute_reply.started":"2026-01-25T14:37:41.137200Z","shell.execute_reply":"2026-01-25T14:37:58.899943Z"},"trusted":true},"outputs":[{"name":"stderr","text":"2026-01-25 14:37:46.795216: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1769351866.990113      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1769351867.048034      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1769351867.519387      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1769351867.519431      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1769351867.519434      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1769351867.519437      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"class VSLDataset(Dataset):\n    def __init__(self, root_dir, label_map_path):\n        self.samples = []\n        self.labels = []\n        self.gloss_to_indices = {}\n\n        with open(label_map_path, \"r\", encoding=\"utf-8\") as f:\n            self.label_map = json.load(f)\n\n        for gloss_name in sorted(os.listdir(root_dir)):\n            gloss_path = os.path.join(root_dir, gloss_name)\n            if not os.path.isdir(gloss_path):\n                continue\n\n            if gloss_name not in self.label_map:\n                raise ValueError(f\"Gloss '{gloss_name}' not found in label_map.json\")\n\n            gloss_id = int(self.label_map[gloss_name])\n\n            for fname in os.listdir(gloss_path):\n                if not fname.endswith(\".npz\"):\n                    continue\n\n                fpath = os.path.join(gloss_path, fname)\n                idx = len(self.samples)\n\n                self.samples.append(fpath)\n                self.labels.append(gloss_id)\n\n                if gloss_id not in self.gloss_to_indices:\n                    self.gloss_to_indices[gloss_id] = []\n                self.gloss_to_indices[gloss_id].append(idx)\n\n    def __len__(self):\n        return len(self.samples)\n\n    def __getitem__(self, idx):\n        npz = np.load(self.samples[idx])\n        x = npz[\"sequence\"]\n        y = self.labels[idx]\n        return x, y","metadata":{"execution":{"iopub.status.busy":"2026-01-25T14:37:58.902183Z","iopub.execute_input":"2026-01-25T14:37:58.902625Z","iopub.status.idle":"2026-01-25T14:37:58.909808Z","shell.execute_reply.started":"2026-01-25T14:37:58.902601Z","shell.execute_reply":"2026-01-25T14:37:58.909052Z"},"trusted":true},"outputs":[],"execution_count":6},{"cell_type":"code","source":"class PKSampler(Sampler):\n    def __init__(self, gloss_to_indices, P=32, K=8, steps_per_epoch=1000):\n        self.gloss_to_indices = gloss_to_indices\n        self.P = P\n        self.K = K\n        self.steps_per_epoch = steps_per_epoch\n\n        self.ptr = {}\n        self.buffers = {}\n\n        # Chỉ giữ gloss đủ K sample\n        self.gloss_ids = [\n            g for g, idxs in gloss_to_indices.items()\n            if len(idxs) >= K\n        ]\n\n        if len(self.gloss_ids) < P:\n            raise ValueError(\n                f\"Not enough glosses with >=K samples: \"\n                f\"{len(self.gloss_ids)} < P={P}\"\n            )\n\n        for g in self.gloss_ids:\n            idxs = gloss_to_indices[g].copy()\n            random.shuffle(idxs)\n            self.buffers[g] = idxs\n            self.ptr[g] = 0\n\n    def __len__(self):\n        # pseudo-length (steps per epoch)\n        return self.steps_per_epoch\n\n    def __iter__(self):\n        for _ in range(self.steps_per_epoch):\n            batch = []\n\n            gloss_batch = random.sample(self.gloss_ids, self.P)\n\n            for g in gloss_batch:\n                idxs = self.buffers[g]\n                p = self.ptr[g]\n\n                if p + self.K > len(idxs):\n                    random.shuffle(idxs)\n                    p = 0\n\n                batch.extend(idxs[p:p + self.K])\n                self.ptr[g] = p + self.K\n\n            yield batch","metadata":{"execution":{"iopub.status.busy":"2026-01-25T14:37:58.910652Z","iopub.execute_input":"2026-01-25T14:37:58.910978Z","iopub.status.idle":"2026-01-25T14:37:59.078335Z","shell.execute_reply.started":"2026-01-25T14:37:58.910956Z","shell.execute_reply":"2026-01-25T14:37:59.077804Z"},"trusted":true},"outputs":[],"execution_count":7},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\nlabel_map_path = \"/kaggle/input/vsl-vietnamese-sign-languages/Processed/label_map.json\"\ntrain_root = \"/kaggle/input/vsl-vietnamese-sign-languages/Processed/train\"\nval_root = \"/kaggle/input/vsl-vietnamese-sign-languages/Processed/val\"\ntest_root = \"/kaggle/input/vsl-vietnamese-sign-languages/Processed/test\"\n\ntrain_ds = VSLDataset(train_root, label_map_path)\nval_ds = VSLDataset(val_root, label_map_path)\ntest_ds = VSLDataset(test_root, label_map_path)\n\nsampler = PKSampler(\n    gloss_to_indices=train_ds.gloss_to_indices,\n    P=32, # Số gloss mỗi step\n    K=4, # Số sequence mỗi step\n    steps_per_epoch=1000 # Số step mỗi epoch\n)\n\ntrain_loader = DataLoader(\n    train_ds,\n    batch_sampler=sampler,\n    num_workers=4,\n    pin_memory=True\n)\n\nval_loader = DataLoader(\n    val_ds,\n    batch_size=256,\n    num_workers=4,\n    pin_memory=True \n)\n\ntest_loader = DataLoader(\n    val_ds,\n    batch_size=256,\n    num_workers=4,\n    pin_memory=True \n)","metadata":{"execution":{"iopub.status.busy":"2026-01-25T14:37:59.079391Z","iopub.execute_input":"2026-01-25T14:37:59.079620Z","iopub.status.idle":"2026-01-25T14:39:04.687209Z","shell.execute_reply.started":"2026-01-25T14:37:59.079600Z","shell.execute_reply":"2026-01-25T14:39:04.686577Z"},"trusted":true},"outputs":[],"execution_count":8},{"cell_type":"code","source":"mp_holistic = mp.solutions.holistic\n\nN_UPPER_BODY_POSE_LANDMARKS = 25\nN_HAND_LANDMARKS = 21\nN_TOTAL_LANDMARKS = 67\n\n\ndef build_adjacency(self_loop=True):\n    A = torch.zeros(N_TOTAL_LANDMARKS, N_TOTAL_LANDMARKS)\n    for i, j in mp_holistic.POSE_CONNECTIONS:\n        if i < N_UPPER_BODY_POSE_LANDMARKS and j < N_UPPER_BODY_POSE_LANDMARKS:\n            A[i, j] = 1\n            A[j, i] = 1\n\n    LEFT_HAND_OFFSET = N_UPPER_BODY_POSE_LANDMARKS\n    for i, j in mp_holistic.HAND_CONNECTIONS:\n        A[LEFT_HAND_OFFSET + i, LEFT_HAND_OFFSET + j] = 1\n        A[LEFT_HAND_OFFSET + j, LEFT_HAND_OFFSET + i] = 1\n\n    RIGHT_HAND_OFFSET = N_UPPER_BODY_POSE_LANDMARKS + N_HAND_LANDMARKS\n    for i, j in mp_holistic.HAND_CONNECTIONS:\n        A[RIGHT_HAND_OFFSET + i, RIGHT_HAND_OFFSET + j] = 1\n        A[RIGHT_HAND_OFFSET + j, RIGHT_HAND_OFFSET + i] = 1\n\n    POSE_LEFT_WRIST = 15\n    POSE_RIGHT_WRIST = 16\n\n    LEFT_HAND_WRIST = LEFT_HAND_OFFSET + 0\n    RIGHT_HAND_WRIST = RIGHT_HAND_OFFSET + 0\n\n    A[POSE_LEFT_WRIST, LEFT_HAND_WRIST] = 1\n    A[LEFT_HAND_WRIST, POSE_LEFT_WRIST] = 1\n\n    A[POSE_RIGHT_WRIST, RIGHT_HAND_WRIST] = 1\n    A[RIGHT_HAND_WRIST, POSE_RIGHT_WRIST] = 1\n\n    if self_loop:\n        A += torch.eye(N_TOTAL_LANDMARKS)\n\n    A = A / A.sum(dim=1, keepdim=True)\n\n    return A\n\nclass MS_GCN(nn.Module):\n    def __init__(self, in_channels, out_channels, A, scales=(1, 2, 3)):\n        super().__init__()\n        self.As = build_multiscale_adjacency(A, scales)\n        self.convs = nn.ModuleList([\n            nn.Conv2d(in_channels, out_channels, kernel_size=1)\n            for _ in scales\n        ])\n\n    def forward(self, x):\n        \"\"\"\n        x: (B, C, T, V)\n        \"\"\"\n        out = 0\n        for A, conv in zip(self.As, self.convs):\n            A = A.to(x.device)\n            z = torch.einsum(\"vw,bctw->bctv\", A, x)\n            out = out + conv(z)\n        return out\n\ndef build_multiscale_adjacency(A, scales=(1, 2, 3)):\n    \"\"\"\n    A: (V, V)\n    return: list of A^k\n    \"\"\"\n    As = []\n    A_k = A.clone()\n    for k in scales:\n        if k == 1:\n            As.append(A)\n        else:\n            A_k = torch.matmul(A_k, A)\n            As.append(A_k)\n    return As\n\n\nclass MS_G3D_Block(nn.Module):\n    def __init__(self, in_channels, out_channels, A, stride=1):\n        super().__init__()\n\n        self.msgcn = MS_GCN(in_channels, out_channels, A)\n\n        self.temporal_conv = nn.Sequential(\n            nn.Conv3d(\n                out_channels,\n                out_channels,\n                kernel_size=(3, 1, 1),\n                stride=(stride, 1, 1),\n                padding=(1, 0, 0)\n            ),\n            nn.BatchNorm3d(out_channels),\n            nn.ReLU(inplace=True)\n        )\n\n        if in_channels != out_channels or stride != 1:\n            self.residual = nn.Conv3d(\n                in_channels,\n                out_channels,\n                kernel_size=1,\n                stride=(stride, 1, 1)\n            )\n        else:\n            self.residual = None\n\n    def forward(self, x):\n        \"\"\"\n        x: (B, C, T, V)\n        return: (B, C, T, V)\n        \"\"\"\n\n        # Residual path\n        if self.residual is not None:\n            res = self.residual(x.unsqueeze(-1))\n        else:\n            res = x.unsqueeze(-1)\n\n        # MS-GCN (4D)\n        x = self.msgcn(x)                  # (B, C, T, V)\n\n        # Temporal Conv (5D)\n        x = self.temporal_conv(x.unsqueeze(-1))  # (B, C, T', V, 1)\n\n        # Add & REMOVE person dim\n        x = x + res\n        x = x.squeeze(-1)                  # ✅ BACK TO (B, C, T, V)\n\n        return x\n\n\n\nclass VSL_MS_G3D(nn.Module):\n    def __init__(\n        self,\n        in_dim=3,\n        hidden_dim=256,\n        emb_dim=256\n    ):\n        super().__init__()\n\n        A = build_adjacency()\n\n        self.data_bn = nn.BatchNorm1d(N_TOTAL_LANDMARKS * in_dim)\n\n        self.block1 = MS_G3D_Block(in_dim, 128, A)\n        self.block2 = MS_G3D_Block(128, 256, A, stride=2)\n        self.block3 = MS_G3D_Block(256, hidden_dim, A)\n\n        self.fc = nn.Linear(hidden_dim, emb_dim)\n\n    def forward(self, x):\n        \"\"\"\n        x: (B, T, V*C)\n        \"\"\"\n        B, T, _ = x.shape\n        x = x.view(B, T, N_TOTAL_LANDMARKS * 3)\n        x = self.data_bn(x.view(B * T, -1)).view(B, T, N_TOTAL_LANDMARKS, 3)\n\n        # (B, C, T, V)\n        x = x.permute(0, 3, 1, 2)\n\n        x = self.block1(x)\n        x = self.block2(x)\n        x = self.block3(x)\n\n        # Global Pooling\n        x = x.mean(dim=[2, 3])  # (B, C)\n\n        emb = self.fc(x)\n        emb = F.normalize(emb, dim=1)\n\n        return emb\n","metadata":{"execution":{"iopub.status.busy":"2026-01-25T14:39:04.688138Z","iopub.execute_input":"2026-01-25T14:39:04.688442Z","iopub.status.idle":"2026-01-25T14:39:04.704342Z","shell.execute_reply.started":"2026-01-25T14:39:04.688417Z","shell.execute_reply":"2026-01-25T14:39:04.703590Z"},"trusted":true},"outputs":[],"execution_count":9},{"cell_type":"code","source":"class SupConLoss(nn.Module):\n    def __init__(self, temperature=0.07):\n        super().__init__()\n        self.temperature = temperature\n\n    def forward(self, features, labels):\n        features = F.normalize(features, dim=1)\n        labels = labels.view(-1, 1)\n\n        mask = torch.eq(labels, labels.T).float().to(features.device)\n\n        logits = torch.matmul(features, features.T) / self.temperature\n        logits = logits - logits.max(dim=1, keepdim=True)[0].detach()\n\n        logits_mask = torch.ones_like(mask)\n        logits_mask.fill_diagonal_(0)\n        mask = mask * logits_mask\n\n        exp_logits = torch.exp(logits) * logits_mask\n        log_prob = logits - torch.log(exp_logits.sum(1, keepdim=True) + 1e-8)\n\n        mean_log_prob_pos = (mask * log_prob).sum(1) / (mask.sum(1) + 1e-8)\n        loss = -mean_log_prob_pos.mean()\n        return loss","metadata":{"execution":{"iopub.status.busy":"2026-01-25T14:39:04.705341Z","iopub.execute_input":"2026-01-25T14:39:04.705572Z","iopub.status.idle":"2026-01-25T14:39:04.726622Z","shell.execute_reply.started":"2026-01-25T14:39:04.705552Z","shell.execute_reply":"2026-01-25T14:39:04.726080Z"},"trusted":true},"outputs":[],"execution_count":10},{"cell_type":"code","source":"def eval_recall_at_k_faiss(\n    model,\n    val_loader,\n    device,\n    Ks=(1, 5)\n):\n    model.eval()\n\n    # ===== 1. Extract embeddings =====\n    all_embs = []\n    all_labels = []\n\n    with torch.no_grad():\n        for x, y in tqdm(val_loader, desc=\"Extract val emb\", leave=False):\n            x = x.to(device).float()\n            emb = model(x)                 # (B, D)\n            emb = F.normalize(emb, dim=1)  # cosine\n\n            all_embs.append(emb.cpu())\n            all_labels.append(y.cpu())\n\n    all_embs = torch.cat(all_embs, dim=0)      # (N, D)\n    all_labels = torch.cat(all_labels, dim=0)  # (N,)\n\n    # ===== 2. FAISS index =====\n    emb_np = all_embs.numpy().astype(\"float32\")\n    labels_np = all_labels.numpy()\n\n    dim = emb_np.shape[1]\n\n    index = faiss.IndexFlatIP(dim)  # Inner Product\n    index.add(emb_np)               # N vectors\n\n    # ===== 3. Search =====\n    max_k = max(Ks) + 1  # +1 để bỏ self-match\n    D, I = index.search(emb_np, max_k)\n\n    recalls = {}\n    for K in Ks:\n        correct = 0\n        for i in range(len(I)):\n            # bỏ chính nó\n            neighbors = I[i][I[i] != i][:K]\n            if labels_np[i] in labels_np[neighbors]:\n                correct += 1\n\n        recalls[K] = correct / len(I)\n\n    return recalls","metadata":{"execution":{"iopub.status.busy":"2026-01-25T14:39:04.727595Z","iopub.execute_input":"2026-01-25T14:39:04.727826Z","iopub.status.idle":"2026-01-25T14:39:04.741322Z","shell.execute_reply.started":"2026-01-25T14:39:04.727806Z","shell.execute_reply":"2026-01-25T14:39:04.740724Z"},"trusted":true},"outputs":[],"execution_count":11},{"cell_type":"code","source":"model = VSL_MS_G3D(\n    in_dim=3,\n    hidden_dim=256,\n    emb_dim=256\n)\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nmodel = model.to(device)\n\ncriterion = SupConLoss(temperature=0.07)\noptimizer = torch.optim.AdamW(\n    model.parameters(), lr=1e-3, weight_decay=1e-4\n)\n\nuse_amp = (device == \"cuda\")\nscaler = GradScaler(enabled=use_amp)\n\nepochs = 5\neval_interval = 1\n\nsave_dir = \"./checkpoints\"\nos.makedirs(save_dir, exist_ok=True)\n\nbest_recall1 = 0.0","metadata":{"execution":{"iopub.status.busy":"2026-01-25T15:52:46.683237Z","iopub.execute_input":"2026-01-25T15:52:46.683899Z","iopub.status.idle":"2026-01-25T15:52:46.707439Z","shell.execute_reply.started":"2026-01-25T15:52:46.683873Z","shell.execute_reply":"2026-01-25T15:52:46.706749Z"},"trusted":true},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_55/11568607.py:16: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = GradScaler(enabled=use_amp)\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"lr_patience = 2\nearly_stop_patience = 6\nbest_recall1 = 0.0\nno_improve_count = 0\n\nlog_path = os.path.join(save_dir, \"train_log.csv\")\n\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n    optimizer,\n    mode=\"max\",\n    factor=0.3,\n    patience=lr_patience,\n    min_lr=1e-6,\n)\n\n\nif not os.path.exists(log_path):\n    with open(log_path, \"w\", newline=\"\") as f:\n        writer = csv.writer(f)\n        writer.writerow([\n            \"epoch\",\n            \"train_loss\",\n            \"recall@1\",\n            \"lr\",\n            \"epoch_time_sec\"\n        ])\n\n\nfor epoch in range(epochs):\n    model.train()\n    epoch_loss = 0.0\n    start_time = time.time()\n\n    pbar = tqdm(\n        train_loader,\n        desc=f\"Epoch {epoch+1}/{epochs}\",\n        ncols=120\n    )\n\n    for step, (x, y) in enumerate(pbar):\n        x = x.to(device).float()\n        y = y.to(device).long()\n\n        optimizer.zero_grad(set_to_none=True)\n\n        with autocast(enabled=use_amp):\n            emb = model(x)\n            loss = criterion(emb, y)\n\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n\n        epoch_loss += loss.item()\n\n        pbar.set_postfix({\n            \"loss\": f\"{loss.item():.4f}\",\n            \"lr\": optimizer.param_groups[0][\"lr\"]\n        })\n\n    avg_loss = epoch_loss / (step + 1)\n    epoch_time = time.time() - start_time\n    current_lr = optimizer.param_groups[0][\"lr\"]\n\n    print(\n        f\"\\nEpoch {epoch+1}: \"\n        f\"train_loss={avg_loss:.4f}, \"\n        f\"lr={current_lr:.2e}, \"\n        f\"time={epoch_time:.1f}s\"\n    )\n\n    # -------- SAVE LAST --------\n    torch.save(\n        {\n            \"epoch\": epoch + 1,\n            \"model\": model.state_dict(),\n            \"optimizer\": optimizer.state_dict(),\n        },\n        f\"{save_dir}/last_encoder.pt\"\n    )\n\n    recall1 = None\n\n    if (epoch + 1) % eval_interval == 0:\n        model.eval()\n        with torch.no_grad():\n            recalls = eval_recall_at_k_faiss(\n                model,\n                val_loader,\n                device,\n                Ks=(1, 5)\n            )\n\n        recall1 = recalls[1]\n\n        print(\n            f\"\\n Valid Epoch {epoch+1} | \"\n            f\"R@1: {recall1*100:.2f}% | \"\n        )\n\n        scheduler.step(recall1)\n\n        if recall1 > best_recall1:\n            best_recall1 = recall1\n            no_improve_count = 0\n\n            torch.save(\n                model.state_dict(),\n                f\"{save_dir}/best_encoder.pt\"\n            )\n            print(\"Saved BEST encoder (Recall@1)\")\n\n        else:\n            no_improve_count += 1\n            print(\n                f\"⏸ No Recall@1 improvement \"\n                f\"({no_improve_count}/{early_stop_patience})\"\n            )\n\n    with open(log_path, \"a\", newline=\"\") as f:\n        writer = csv.writer(f)\n        writer.writerow([\n            epoch + 1,\n            round(avg_loss, 6),\n            None if recall1 is None else round(recall1, 6),\n            f\"{current_lr:.2e}\",\n            round(epoch_time, 2)\n        ])\n\n    if no_improve_count >= early_stop_patience:\n        print(\n            f\"\\nEarly stopping at epoch {epoch+1} \"\n            f\"(no Recall@1 improvement for \"\n            f\"{early_stop_patience} evals)\"\n        )\n        break\n\nprint(\"Encoder training finished\")\n","metadata":{"execution":{"iopub.status.busy":"2026-01-25T14:39:07.778156Z","iopub.execute_input":"2026-01-25T14:39:07.778706Z","iopub.status.idle":"2026-01-25T15:33:25.998704Z","shell.execute_reply.started":"2026-01-25T14:39:07.778681Z","shell.execute_reply":"2026-01-25T15:33:25.997959Z"},"trusted":true},"outputs":[{"name":"stderr","text":"Epoch 1/5:   0%|                                                                               | 0/1000 [00:00<?, ?it/s]/tmp/ipykernel_55/883657663.py:46: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=use_amp):\nEpoch 1/5: 100%|█████████████████████████████████████████████| 1000/1000 [10:24<00:00,  1.60it/s, loss=1.4466, lr=0.001]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: train_loss=1.7749, lr=1.00e-03, time=624.2s\n","output_type":"stream"},{"name":"stderr","text":"                                                                \r","output_type":"stream"},{"name":"stdout","text":"\n Valid Epoch 1 | R@1: 99.17% | \nSaved BEST encoder (Recall@1)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/5: 100%|█████████████████████████████████████████████| 1000/1000 [10:22<00:00,  1.61it/s, loss=1.5192, lr=0.001]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 2: train_loss=1.5390, lr=1.00e-03, time=622.3s\n","output_type":"stream"},{"name":"stderr","text":"                                                                \r","output_type":"stream"},{"name":"stdout","text":"\n Valid Epoch 2 | R@1: 99.75% | \nSaved BEST encoder (Recall@1)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/5: 100%|█████████████████████████████████████████████| 1000/1000 [10:22<00:00,  1.61it/s, loss=1.3844, lr=0.001]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 3: train_loss=1.4775, lr=1.00e-03, time=622.5s\n","output_type":"stream"},{"name":"stderr","text":"                                                                \r","output_type":"stream"},{"name":"stdout","text":"\n Valid Epoch 3 | R@1: 99.65% | \n⏸ No Recall@1 improvement (1/6)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/5: 100%|█████████████████████████████████████████████| 1000/1000 [10:22<00:00,  1.61it/s, loss=1.6228, lr=0.001]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 4: train_loss=1.4540, lr=1.00e-03, time=622.2s\n","output_type":"stream"},{"name":"stderr","text":"                                                                \r","output_type":"stream"},{"name":"stdout","text":"\n Valid Epoch 4 | R@1: 99.74% | \n⏸ No Recall@1 improvement (2/6)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/5: 100%|█████████████████████████████████████████████| 1000/1000 [10:22<00:00,  1.61it/s, loss=1.4208, lr=0.001]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 5: train_loss=1.4268, lr=1.00e-03, time=622.0s\n","output_type":"stream"},{"name":"stderr","text":"                                                                \r","output_type":"stream"},{"name":"stdout","text":"\n Valid Epoch 5 | R@1: 99.76% | \nSaved BEST encoder (Recall@1)\nEncoder training finished\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"model_dir = \"./checkpoints\"\n\nmodel = VSL_MS_G3D(\n    in_dim=3,\n    hidden_dim=256,\n    emb_dim=256\n)\n\nmodel.to(\"cuda\")\n\nckpt_path = f\"{model_dir}/best_encoder.pt\"\nmodel.load_state_dict(torch.load(ckpt_path, map_location=device))\n\nrecalls = eval_recall_at_k_faiss(\n            model,\n            test_loader,\n            device,\n            Ks=(1, 5)\n        )\n\nrecall1 = recalls[1]\nrecall5 = recalls[5]\n\nprint(\n    f\"\\n Valid | \"\n    f\"R@1: {recall1*100:.2f}% | \"\n    f\"R@5: {recall5*100:.2f}%\"\n)","metadata":{"execution":{"iopub.status.busy":"2026-01-25T15:55:13.260865Z","iopub.execute_input":"2026-01-25T15:55:13.261285Z","iopub.status.idle":"2026-01-25T15:55:41.364305Z","shell.execute_reply.started":"2026-01-25T15:55:13.261246Z","shell.execute_reply":"2026-01-25T15:55:41.363556Z"},"trusted":true},"outputs":[{"name":"stderr","text":"                                                                \r","output_type":"stream"},{"name":"stdout","text":"\n Valid | R@1: 99.76% | R@5: 99.82%\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"!zip best.zip ./checkpoints/best_encoder.pt","metadata":{"execution":{"iopub.status.busy":"2026-01-25T16:07:47.642256Z","iopub.execute_input":"2026-01-25T16:07:47.642608Z","iopub.status.idle":"2026-01-25T16:07:47.970900Z","shell.execute_reply.started":"2026-01-25T16:07:47.642576Z","shell.execute_reply":"2026-01-25T16:07:47.970217Z"},"trusted":true},"outputs":[{"name":"stdout","text":"updating: checkpoints/best_encoder.pt (deflated 8%)\n","output_type":"stream"}],"execution_count":22}]}