{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.12"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":14603584,"sourceType":"datasetVersion","datasetId":9273717}],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%pip install -q faiss-cpu mediapipe==0.10.14","metadata":{"execution":{"iopub.status.busy":"2026-01-25T20:15:12.549219Z","iopub.execute_input":"2026-01-25T20:15:12.549753Z","iopub.status.idle":"2026-01-25T20:15:20.595572Z","shell.execute_reply.started":"2026-01-25T20:15:12.549725Z","shell.execute_reply":"2026-01-25T20:15:20.594810Z"},"trusted":true},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.7/35.7 MB\u001b[0m \u001b[31m45.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.8/23.8 MB\u001b[0m \u001b[31m71.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngoogle-adk 1.22.1 requires google-cloud-bigquery-storage>=2.0.0, which is not installed.\nbigframes 2.26.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\na2a-sdk 0.3.22 requires protobuf>=5.29.5, but you have protobuf 4.25.8 which is incompatible.\nopentelemetry-proto 1.37.0 requires protobuf<7.0,>=5.0, but you have protobuf 4.25.8 which is incompatible.\nydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 4.25.8 which is incompatible.\nbigframes 2.26.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\ngrpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.8 which is incompatible.\ngcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.10.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\", category=RuntimeWarning)","metadata":{"execution":{"iopub.status.busy":"2026-01-25T20:15:31.216901Z","iopub.execute_input":"2026-01-25T20:15:31.217399Z","iopub.status.idle":"2026-01-25T20:15:31.221010Z","shell.execute_reply.started":"2026-01-25T20:15:31.217372Z","shell.execute_reply":"2026-01-25T20:15:31.220307Z"},"trusted":true},"outputs":[],"execution_count":3},{"cell_type":"code","source":"import os\nimport numpy as np\nimport random\nimport json\nfrom torch.utils.data import Dataset, Sampler\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.cuda.amp import GradScaler, autocast\nfrom tqdm import tqdm\nimport time\nimport faiss\nimport csv\nimport mediapipe as mp","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2026-01-25T20:16:16.422152Z","iopub.execute_input":"2026-01-25T20:16:16.422963Z","iopub.status.idle":"2026-01-25T20:16:16.427176Z","shell.execute_reply.started":"2026-01-25T20:16:16.422931Z","shell.execute_reply":"2026-01-25T20:16:16.426508Z"},"trusted":true},"outputs":[],"execution_count":5},{"cell_type":"code","source":"class VSLDataset(Dataset):\n    def __init__(self, root_dir, label_map_path):\n        self.samples = []\n        self.labels = []\n        self.gloss_to_indices = {}\n\n        with open(label_map_path, \"r\", encoding=\"utf-8\") as f:\n            self.label_map = json.load(f)\n\n        for gloss_name in sorted(os.listdir(root_dir)):\n            gloss_path = os.path.join(root_dir, gloss_name)\n            if not os.path.isdir(gloss_path):\n                continue\n\n            if gloss_name not in self.label_map:\n                raise ValueError(f\"Gloss '{gloss_name}' not found in label_map.json\")\n\n            gloss_id = int(self.label_map[gloss_name])\n\n            for fname in os.listdir(gloss_path):\n                if not fname.endswith(\".npz\"):\n                    continue\n\n                fpath = os.path.join(gloss_path, fname)\n                idx = len(self.samples)\n\n                self.samples.append(fpath)\n                self.labels.append(gloss_id)\n\n                if gloss_id not in self.gloss_to_indices:\n                    self.gloss_to_indices[gloss_id] = []\n                self.gloss_to_indices[gloss_id].append(idx)\n\n    def __len__(self):\n        return len(self.samples)\n\n    def __getitem__(self, idx):\n        npz = np.load(self.samples[idx])\n        x = npz[\"sequence\"]\n        y = self.labels[idx]\n        return x, y","metadata":{"execution":{"iopub.status.busy":"2026-01-25T20:16:27.231033Z","iopub.execute_input":"2026-01-25T20:16:27.231810Z","iopub.status.idle":"2026-01-25T20:16:27.238470Z","shell.execute_reply.started":"2026-01-25T20:16:27.231777Z","shell.execute_reply":"2026-01-25T20:16:27.237625Z"},"trusted":true},"outputs":[],"execution_count":10},{"cell_type":"code","source":"class PKSampler(Sampler):\n    def __init__(self, gloss_to_indices, P=32, K=8, steps_per_epoch=1000):\n        self.gloss_to_indices = gloss_to_indices\n        self.P = P\n        self.K = K\n        self.steps_per_epoch = steps_per_epoch\n\n        self.ptr = {}\n        self.buffers = {}\n\n        # Chỉ giữ gloss đủ K sample\n        self.gloss_ids = [\n            g for g, idxs in gloss_to_indices.items()\n            if len(idxs) >= K\n        ]\n\n        if len(self.gloss_ids) < P:\n            raise ValueError(\n                f\"Not enough glosses with >=K samples: \"\n                f\"{len(self.gloss_ids)} < P={P}\"\n            )\n\n        for g in self.gloss_ids:\n            idxs = gloss_to_indices[g].copy()\n            random.shuffle(idxs)\n            self.buffers[g] = idxs\n            self.ptr[g] = 0\n\n    def __len__(self):\n        # pseudo-length (steps per epoch)\n        return self.steps_per_epoch\n\n    def __iter__(self):\n        for _ in range(self.steps_per_epoch):\n            batch = []\n\n            gloss_batch = random.sample(self.gloss_ids, self.P)\n\n            for g in gloss_batch:\n                idxs = self.buffers[g]\n                p = self.ptr[g]\n\n                if p + self.K > len(idxs):\n                    random.shuffle(idxs)\n                    p = 0\n\n                batch.extend(idxs[p:p + self.K])\n                self.ptr[g] = p + self.K\n\n            yield batch","metadata":{"execution":{"iopub.status.busy":"2026-01-25T20:16:30.433821Z","iopub.execute_input":"2026-01-25T20:16:30.434144Z","iopub.status.idle":"2026-01-25T20:16:30.442744Z","shell.execute_reply.started":"2026-01-25T20:16:30.434115Z","shell.execute_reply":"2026-01-25T20:16:30.441926Z"},"trusted":true},"outputs":[],"execution_count":11},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\nlabel_map_path = \"/kaggle/input/vsl-vietnamese-sign-languages/Processed/label_map.json\"\ntrain_root = \"/kaggle/input/vsl-vietnamese-sign-languages/Processed/train\"\nval_root = \"/kaggle/input/vsl-vietnamese-sign-languages/Processed/val\"\ntest_root = \"/kaggle/input/vsl-vietnamese-sign-languages/Processed/test\"\n\ntrain_ds = VSLDataset(train_root, label_map_path)\nval_ds = VSLDataset(val_root, label_map_path)\ntest_ds = VSLDataset(test_root, label_map_path)\n\nsampler = PKSampler(\n    gloss_to_indices=train_ds.gloss_to_indices,\n    P=32, # Số gloss mỗi step\n    K=4, # Số sequence mỗi step\n    steps_per_epoch=1000 # Số step mỗi epoch\n)\n\ntrain_loader = DataLoader(\n    train_ds,\n    batch_sampler=sampler,\n    num_workers=4,\n    pin_memory=True\n)\n\nval_loader = DataLoader(\n    val_ds,\n    batch_size=256,\n    num_workers=4,\n    pin_memory=True \n)\n\ntest_loader = DataLoader(\n    val_ds,\n    batch_size=256,\n    num_workers=4,\n    pin_memory=True \n)","metadata":{"execution":{"iopub.status.busy":"2026-01-25T20:16:34.826698Z","iopub.execute_input":"2026-01-25T20:16:34.826985Z","iopub.status.idle":"2026-01-25T20:17:36.892467Z","shell.execute_reply.started":"2026-01-25T20:16:34.826960Z","shell.execute_reply":"2026-01-25T20:17:36.891673Z"},"trusted":true},"outputs":[],"execution_count":12},{"cell_type":"code","source":"mp_holistic = mp.solutions.holistic\n\nN_UPPER_BODY_POSE_LANDMARKS = 25\nN_HAND_LANDMARKS = 21\nN_TOTAL_LANDMARKS = 67\n\n\ndef build_adjacency(self_loop=True):\n    A = torch.zeros(N_TOTAL_LANDMARKS, N_TOTAL_LANDMARKS)\n    for i, j in mp_holistic.POSE_CONNECTIONS:\n        if i < N_UPPER_BODY_POSE_LANDMARKS and j < N_UPPER_BODY_POSE_LANDMARKS:\n            A[i, j] = 1\n            A[j, i] = 1\n\n    LEFT_HAND_OFFSET = N_UPPER_BODY_POSE_LANDMARKS\n    for i, j in mp_holistic.HAND_CONNECTIONS:\n        A[LEFT_HAND_OFFSET + i, LEFT_HAND_OFFSET + j] = 1\n        A[LEFT_HAND_OFFSET + j, LEFT_HAND_OFFSET + i] = 1\n\n    RIGHT_HAND_OFFSET = N_UPPER_BODY_POSE_LANDMARKS + N_HAND_LANDMARKS\n    for i, j in mp_holistic.HAND_CONNECTIONS:\n        A[RIGHT_HAND_OFFSET + i, RIGHT_HAND_OFFSET + j] = 1\n        A[RIGHT_HAND_OFFSET + j, RIGHT_HAND_OFFSET + i] = 1\n\n    POSE_LEFT_WRIST = 15\n    POSE_RIGHT_WRIST = 16\n\n    LEFT_HAND_WRIST = LEFT_HAND_OFFSET + 0\n    RIGHT_HAND_WRIST = RIGHT_HAND_OFFSET + 0\n\n    A[POSE_LEFT_WRIST, LEFT_HAND_WRIST] = 1\n    A[LEFT_HAND_WRIST, POSE_LEFT_WRIST] = 1\n\n    A[POSE_RIGHT_WRIST, RIGHT_HAND_WRIST] = 1\n    A[RIGHT_HAND_WRIST, POSE_RIGHT_WRIST] = 1\n\n    if self_loop:\n        A += torch.eye(N_TOTAL_LANDMARKS)\n\n    A = A / A.sum(dim=1, keepdim=True)\n\n    return A\n\n\nclass GCNLayer(nn.Module):\n    def __init__(self, in_dim, out_dim, A):\n        super().__init__()\n        self.register_buffer(\"A\", A)\n        self.fc = nn.Linear(in_dim, out_dim)\n\n    def forward(self, x):\n        # x: (B*T, V, C)\n        x = torch.einsum(\"vw,bwc->bvc\", self.A, x)\n        x = self.fc(x)\n        return x\n\n\nclass CTRGCNBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, A, stride=1):\n        super().__init__()\n\n        self.gcn = CTRGC(in_channels, out_channels, A)\n\n        self.tcn = nn.Sequential(\n            nn.Conv2d(\n                out_channels,\n                out_channels,\n                kernel_size=(9, 1),\n                stride=(stride, 1),\n                padding=(4, 0)\n            ),\n            nn.BatchNorm2d(out_channels)\n        )\n\n        if in_channels != out_channels or stride != 1:\n            self.residual = nn.Sequential(\n                nn.Conv2d(in_channels, out_channels, 1, stride=(stride, 1)),\n                nn.BatchNorm2d(out_channels)\n            )\n        else:\n            self.residual = nn.Identity()\n\n        self.relu = nn.ReLU(inplace=True)\n\n    def forward(self, x):\n        \"\"\"\n        x: (B, C, T, V)\n        \"\"\"\n        res = self.residual(x)\n        x = self.gcn(x)\n        x = self.tcn(x)\n        return self.relu(x + res)\n\nclass CTRGC(nn.Module):\n    def __init__(self, in_channels, out_channels, A):\n        super().__init__()\n        self.A = A\n        inter_channels = out_channels // 4\n\n        self.theta = nn.Conv2d(in_channels, inter_channels, 1)\n        self.phi   = nn.Conv2d(in_channels, inter_channels, 1)\n        self.g     = nn.Conv2d(in_channels, out_channels, 1)\n\n        self.alpha = nn.Parameter(torch.zeros(1))\n        self.bn = nn.BatchNorm2d(out_channels)\n\n    def forward(self, x):\n        \"\"\"\n        x: (B, C, T, V)\n        \"\"\"\n        B, C, T, V = x.shape\n\n        # Feature embedding\n        theta = self.theta(x).mean(dim=2)   # (B, C', V)\n        phi   = self.phi(x).mean(dim=2)     # (B, C', V)\n\n        # Dynamic adjacency (B, V, V)\n        A_dyn = torch.tanh(\n            theta.unsqueeze(-1) - phi.unsqueeze(-2)\n        ).mean(dim=1)\n\n        # Final adjacency\n        A = self.A.to(x.device)\n        A = A.unsqueeze(0) + self.alpha * A_dyn\n\n        # Graph convolution\n        x = x.mean(dim=2)                   # (B, C, V)\n        x = torch.einsum(\"bcv,bvw->bcw\", x, A)\n        x = x.unsqueeze(2).repeat(1, 1, T, 1)\n\n        x = self.g(x)\n        x = self.bn(x)\n        return x\n\n\nclass VSL_CTR_GCN(nn.Module):\n    def __init__(\n        self,\n        in_dim=3,\n        hidden_dim=256,\n        emb_dim=256\n    ):\n        super().__init__()\n\n        A = build_adjacency()\n\n        self.data_bn = nn.BatchNorm1d(N_TOTAL_LANDMARKS * in_dim)\n\n        self.block1 = CTRGCNBlock(in_dim, 64, A)\n        self.block2 = CTRGCNBlock(64, 128, A, stride=2)\n        self.block3 = CTRGCNBlock(128, hidden_dim, A)\n\n        self.fc = nn.Linear(hidden_dim, emb_dim)\n\n    def forward(self, x):\n        \"\"\"\n        x: (B, T, V*C)\n        \"\"\"\n        B, T, _ = x.shape\n\n        # giữ logic reshape cũ\n        x = x.view(B, T, N_TOTAL_LANDMARKS * 3)\n        x = self.data_bn(x.view(B * T, -1)).view(B, T, N_TOTAL_LANDMARKS, 3)\n\n        # (B, C, T, V)\n        x = x.permute(0, 3, 1, 2)\n\n        x = self.block1(x)\n        x = self.block2(x)\n        x = self.block3(x)\n\n        # Global pooling\n        x = x.mean(dim=[2, 3])  # (B, C)\n\n        emb = self.fc(x)\n        emb = F.normalize(emb, dim=1)\n\n        return emb\n\n","metadata":{"execution":{"iopub.status.busy":"2026-01-25T20:23:56.236575Z","iopub.execute_input":"2026-01-25T20:23:56.237284Z","iopub.status.idle":"2026-01-25T20:23:56.254270Z","shell.execute_reply.started":"2026-01-25T20:23:56.237255Z","shell.execute_reply":"2026-01-25T20:23:56.253591Z"},"trusted":true},"outputs":[],"execution_count":27},{"cell_type":"code","source":"class SupConLoss(nn.Module):\n    def __init__(self, temperature=0.07):\n        super().__init__()\n        self.temperature = temperature\n\n    def forward(self, features, labels):\n        features = F.normalize(features, dim=1)\n        labels = labels.view(-1, 1)\n\n        mask = torch.eq(labels, labels.T).float().to(features.device)\n\n        logits = torch.matmul(features, features.T) / self.temperature\n        logits = logits - logits.max(dim=1, keepdim=True)[0].detach()\n\n        logits_mask = torch.ones_like(mask)\n        logits_mask.fill_diagonal_(0)\n        mask = mask * logits_mask\n\n        exp_logits = torch.exp(logits) * logits_mask\n        log_prob = logits - torch.log(exp_logits.sum(1, keepdim=True) + 1e-8)\n\n        mean_log_prob_pos = (mask * log_prob).sum(1) / (mask.sum(1) + 1e-8)\n        loss = -mean_log_prob_pos.mean()\n        return loss","metadata":{"execution":{"iopub.status.busy":"2026-01-25T20:18:03.980189Z","iopub.execute_input":"2026-01-25T20:18:03.980783Z","iopub.status.idle":"2026-01-25T20:18:03.986576Z","shell.execute_reply.started":"2026-01-25T20:18:03.980753Z","shell.execute_reply":"2026-01-25T20:18:03.985854Z"},"trusted":true},"outputs":[],"execution_count":14},{"cell_type":"code","source":"def eval_recall_at_k_faiss(\n    model,\n    val_loader,\n    device,\n    Ks=(1, 5)\n):\n    model.eval()\n\n    # ===== 1. Extract embeddings =====\n    all_embs = []\n    all_labels = []\n\n    with torch.no_grad():\n        for x, y in tqdm(val_loader, desc=\"Extract val emb\", leave=False):\n            x = x.to(device).float()\n            emb = model(x)                 # (B, D)\n            emb = F.normalize(emb, dim=1)  # cosine\n\n            all_embs.append(emb.cpu())\n            all_labels.append(y.cpu())\n\n    all_embs = torch.cat(all_embs, dim=0)      # (N, D)\n    all_labels = torch.cat(all_labels, dim=0)  # (N,)\n\n    # ===== 2. FAISS index =====\n    emb_np = all_embs.numpy().astype(\"float32\")\n    labels_np = all_labels.numpy()\n\n    dim = emb_np.shape[1]\n\n    index = faiss.IndexFlatIP(dim)  # Inner Product\n    index.add(emb_np)               # N vectors\n\n    # ===== 3. Search =====\n    max_k = max(Ks) + 1  # +1 để bỏ self-match\n    D, I = index.search(emb_np, max_k)\n\n    recalls = {}\n    for K in Ks:\n        correct = 0\n        for i in range(len(I)):\n            # bỏ chính nó\n            neighbors = I[i][I[i] != i][:K]\n            if labels_np[i] in labels_np[neighbors]:\n                correct += 1\n\n        recalls[K] = correct / len(I)\n\n    return recalls","metadata":{"execution":{"iopub.status.busy":"2026-01-25T20:24:06.291297Z","iopub.execute_input":"2026-01-25T20:24:06.292052Z","iopub.status.idle":"2026-01-25T20:24:06.298934Z","shell.execute_reply.started":"2026-01-25T20:24:06.292019Z","shell.execute_reply":"2026-01-25T20:24:06.298106Z"},"trusted":true},"outputs":[],"execution_count":29},{"cell_type":"code","source":"model = VSL_CTR_GCN(\n    in_dim=3,\n    hidden_dim=256,\n    emb_dim=256\n)\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nmodel = model.to(device)\n\ncriterion = SupConLoss(temperature=0.07)\noptimizer = torch.optim.AdamW(\n    model.parameters(), lr=1e-3, weight_decay=1e-4\n)\n\nuse_amp = (device == \"cuda\")\nscaler = GradScaler(enabled=use_amp)\n\nepochs = 5\neval_interval = 1\n\nsave_dir = \"./checkpoints\"\nos.makedirs(save_dir, exist_ok=True)\n\nbest_recall1 = 0.0","metadata":{"execution":{"iopub.status.busy":"2026-01-25T20:24:11.811051Z","iopub.execute_input":"2026-01-25T20:24:11.811726Z","iopub.status.idle":"2026-01-25T20:24:11.833578Z","shell.execute_reply.started":"2026-01-25T20:24:11.811696Z","shell.execute_reply":"2026-01-25T20:24:11.832784Z"},"trusted":true},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_55/2479638871.py:16: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = GradScaler(enabled=use_amp)\n","output_type":"stream"}],"execution_count":31},{"cell_type":"code","source":"lr_patience = 2\nearly_stop_patience = 6\nbest_recall1 = 0.0\nno_improve_count = 0\n\nlog_path = os.path.join(save_dir, \"train_log.csv\")\n\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n    optimizer,\n    mode=\"max\",\n    factor=0.3,\n    patience=lr_patience,\n    min_lr=1e-6,\n)\n\n\nif not os.path.exists(log_path):\n    with open(log_path, \"w\", newline=\"\") as f:\n        writer = csv.writer(f)\n        writer.writerow([\n            \"epoch\",\n            \"train_loss\",\n            \"recall@1\",\n            \"lr\",\n            \"epoch_time_sec\"\n        ])\n\n\nfor epoch in range(epochs):\n    model.train()\n    epoch_loss = 0.0\n    start_time = time.time()\n\n    pbar = tqdm(\n        train_loader,\n        desc=f\"Epoch {epoch+1}/{epochs}\",\n        ncols=120\n    )\n\n    for step, (x, y) in enumerate(pbar):\n        x = x.to(device).float()\n        y = y.to(device).long()\n\n        optimizer.zero_grad(set_to_none=True)\n\n        with autocast(enabled=use_amp):\n            emb = model(x)\n            loss = criterion(emb, y)\n\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n\n        epoch_loss += loss.item()\n\n        pbar.set_postfix({\n            \"loss\": f\"{loss.item():.4f}\",\n            \"lr\": optimizer.param_groups[0][\"lr\"]\n        })\n\n    avg_loss = epoch_loss / (step + 1)\n    epoch_time = time.time() - start_time\n    current_lr = optimizer.param_groups[0][\"lr\"]\n\n    print(\n        f\"\\nEpoch {epoch+1}: \"\n        f\"train_loss={avg_loss:.4f}, \"\n        f\"lr={current_lr:.2e}, \"\n        f\"time={epoch_time:.1f}s\"\n    )\n\n    # -------- SAVE LAST --------\n    torch.save(\n        {\n            \"epoch\": epoch + 1,\n            \"model\": model.state_dict(),\n            \"optimizer\": optimizer.state_dict(),\n        },\n        f\"{save_dir}/last_encoder.pt\"\n    )\n\n    recall1 = None\n\n    if (epoch + 1) % eval_interval == 0:\n        model.eval()\n        with torch.no_grad():\n            recalls = eval_recall_at_k_faiss(\n                model,\n                val_loader,\n                device,\n                Ks=(1, 5)\n            )\n\n        recall1 = recalls[1]\n\n        print(\n            f\"\\n Valid Epoch {epoch+1} | \"\n            f\"R@1: {recall1*100:.2f}% | \"\n        )\n\n        scheduler.step(recall1)\n\n        if recall1 > best_recall1:\n            best_recall1 = recall1\n            no_improve_count = 0\n\n            torch.save(\n                model.state_dict(),\n                f\"{save_dir}/best_encoder.pt\"\n            )\n            print(\"Saved BEST encoder (Recall@1)\")\n\n        else:\n            no_improve_count += 1\n            print(\n                f\"⏸ No Recall@1 improvement \"\n                f\"({no_improve_count}/{early_stop_patience})\"\n            )\n\n    with open(log_path, \"a\", newline=\"\") as f:\n        writer = csv.writer(f)\n        writer.writerow([\n            epoch + 1,\n            round(avg_loss, 6),\n            None if recall1 is None else round(recall1, 6),\n            f\"{current_lr:.2e}\",\n            round(epoch_time, 2)\n        ])\n\n    if no_improve_count >= early_stop_patience:\n        print(\n            f\"\\nEarly stopping at epoch {epoch+1} \"\n            f\"(no Recall@1 improvement for \"\n            f\"{early_stop_patience} evals)\"\n        )\n        break\n\nprint(\"Encoder training finished\")\n","metadata":{"execution":{"iopub.status.busy":"2026-01-25T20:24:15.366273Z","iopub.execute_input":"2026-01-25T20:24:15.366910Z","iopub.status.idle":"2026-01-25T20:52:27.530260Z","shell.execute_reply.started":"2026-01-25T20:24:15.366875Z","shell.execute_reply":"2026-01-25T20:52:27.529392Z"},"trusted":true},"outputs":[{"name":"stderr","text":"Epoch 1/5:   0%|                                                                               | 0/1000 [00:00<?, ?it/s]/tmp/ipykernel_55/883657663.py:46: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=use_amp):\nEpoch 1/5: 100%|█████████████████████████████████████████████| 1000/1000 [05:21<00:00,  3.11it/s, loss=1.6724, lr=0.001]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: train_loss=1.5979, lr=1.00e-03, time=321.9s\n","output_type":"stream"},{"name":"stderr","text":"                                                                \r","output_type":"stream"},{"name":"stdout","text":"\n Valid Epoch 1 | R@1: 99.53% | \nSaved BEST encoder (Recall@1)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/5: 100%|█████████████████████████████████████████████| 1000/1000 [05:20<00:00,  3.12it/s, loss=1.3225, lr=0.001]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 2: train_loss=1.4300, lr=1.00e-03, time=320.4s\n","output_type":"stream"},{"name":"stderr","text":"                                                                \r","output_type":"stream"},{"name":"stdout","text":"\n Valid Epoch 2 | R@1: 99.73% | \nSaved BEST encoder (Recall@1)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/5: 100%|█████████████████████████████████████████████| 1000/1000 [05:20<00:00,  3.12it/s, loss=1.1729, lr=0.001]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 3: train_loss=1.3896, lr=1.00e-03, time=320.3s\n","output_type":"stream"},{"name":"stderr","text":"                                                                \r","output_type":"stream"},{"name":"stdout","text":"\n Valid Epoch 3 | R@1: 99.78% | \nSaved BEST encoder (Recall@1)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/5: 100%|█████████████████████████████████████████████| 1000/1000 [05:20<00:00,  3.12it/s, loss=1.4377, lr=0.001]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 4: train_loss=1.3476, lr=1.00e-03, time=320.4s\n","output_type":"stream"},{"name":"stderr","text":"                                                                \r","output_type":"stream"},{"name":"stdout","text":"\n Valid Epoch 4 | R@1: 99.76% | \n⏸ No Recall@1 improvement (1/6)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/5: 100%|█████████████████████████████████████████████| 1000/1000 [05:20<00:00,  3.12it/s, loss=1.2931, lr=0.001]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 5: train_loss=1.3255, lr=1.00e-03, time=320.4s\n","output_type":"stream"},{"name":"stderr","text":"                                                                \r","output_type":"stream"},{"name":"stdout","text":"\n Valid Epoch 5 | R@1: 99.76% | \n⏸ No Recall@1 improvement (2/6)\nEncoder training finished\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"model_dir = \"./checkpoints\"\n\nmodel = VSL_CTR_GCN(\n     in_dim=3,\n     hidden_dim=256,\n     emb_dim=256\n)\n\nmodel.to(\"cuda\")\n\nckpt_path = f\"{model_dir}/best_encoder.pt\"\nmodel.load_state_dict(torch.load(ckpt_path, map_location=device))\n\nrecalls = eval_recall_at_k_faiss(\n            model,\n            test_loader,\n            device,\n            Ks=(1, 5)\n        )\n\nrecall1 = recalls[1]\nrecall5 = recalls[5]\n\nprint(\n    f\"\\n Valid | \"\n    f\"R@1: {recall1*100:.2f}% | \"\n    f\"R@5: {recall5*100:.2f}%\"\n)","metadata":{"execution":{"iopub.status.busy":"2026-01-25T21:11:04.783344Z","iopub.execute_input":"2026-01-25T21:11:04.783674Z","iopub.status.idle":"2026-01-25T21:11:19.913353Z","shell.execute_reply.started":"2026-01-25T21:11:04.783645Z","shell.execute_reply":"2026-01-25T21:11:19.912621Z"},"trusted":true},"outputs":[{"name":"stderr","text":"                                                                \r","output_type":"stream"},{"name":"stdout","text":"\n Valid | R@1: 99.78% | R@5: 99.84%\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"!zip best.zip ./checkpoints/best_encoder.pt","metadata":{"execution":{"iopub.status.busy":"2026-01-25T21:12:48.761444Z","iopub.execute_input":"2026-01-25T21:12:48.762413Z","iopub.status.idle":"2026-01-25T21:12:49.115748Z","shell.execute_reply.started":"2026-01-25T21:12:48.762374Z","shell.execute_reply":"2026-01-25T21:12:49.115008Z"},"trusted":true},"outputs":[{"name":"stdout","text":"  adding: checkpoints/best_encoder.pt (deflated 8%)\n","output_type":"stream"}],"execution_count":35}]}