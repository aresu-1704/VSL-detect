{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6b4865e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T15:46:01.083938Z",
     "iopub.status.busy": "2026-01-25T15:46:01.083671Z",
     "iopub.status.idle": "2026-01-25T15:46:08.909593Z",
     "shell.execute_reply": "2026-01-25T15:46:08.908747Z"
    },
    "papermill": {
     "duration": 7.831587,
     "end_time": "2026-01-25T15:46:08.911293",
     "exception": false,
     "start_time": "2026-01-25T15:46:01.079706",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.7/35.7 MB\u001b[0m \u001b[31m56.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.8/23.8 MB\u001b[0m \u001b[31m92.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "google-adk 1.22.1 requires google-cloud-bigquery-storage>=2.0.0, which is not installed.\r\n",
      "bigframes 2.26.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\r\n",
      "a2a-sdk 0.3.22 requires protobuf>=5.29.5, but you have protobuf 4.25.8 which is incompatible.\r\n",
      "opentelemetry-proto 1.37.0 requires protobuf<7.0,>=5.0, but you have protobuf 4.25.8 which is incompatible.\r\n",
      "ydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 4.25.8 which is incompatible.\r\n",
      "bigframes 2.26.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\r\n",
      "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.8 which is incompatible.\r\n",
      "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.10.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q faiss-cpu mediapipe==0.10.14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8bc4d6a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T15:46:08.919074Z",
     "iopub.status.busy": "2026-01-25T15:46:08.918526Z",
     "iopub.status.idle": "2026-01-25T15:46:08.922184Z",
     "shell.execute_reply": "2026-01-25T15:46:08.921563Z"
    },
    "papermill": {
     "duration": 0.009164,
     "end_time": "2026-01-25T15:46:08.923665",
     "exception": false,
     "start_time": "2026-01-25T15:46:08.914501",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "413610a0",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2026-01-25T15:46:08.930110Z",
     "iopub.status.busy": "2026-01-25T15:46:08.929911Z",
     "iopub.status.idle": "2026-01-25T15:46:27.923748Z",
     "shell.execute_reply": "2026-01-25T15:46:27.922986Z"
    },
    "papermill": {
     "duration": 18.999106,
     "end_time": "2026-01-25T15:46:27.925547",
     "exception": false,
     "start_time": "2026-01-25T15:46:08.926441",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-25 15:46:14.693131: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1769355974.865402      24 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1769355974.916383      24 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1769355975.314699      24 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1769355975.314740      24 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1769355975.314743      24 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1769355975.314746      24 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import json\n",
    "from torch.utils.data import Dataset, Sampler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import faiss\n",
    "import csv\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "808d9369",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T15:46:27.933100Z",
     "iopub.status.busy": "2026-01-25T15:46:27.932383Z",
     "iopub.status.idle": "2026-01-25T15:46:27.940197Z",
     "shell.execute_reply": "2026-01-25T15:46:27.939595Z"
    },
    "papermill": {
     "duration": 0.012874,
     "end_time": "2026-01-25T15:46:27.941474",
     "exception": false,
     "start_time": "2026-01-25T15:46:27.928600",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class VSLDataset(Dataset):\n",
    "    def __init__(self, root_dir, label_map_path):\n",
    "        self.samples = []\n",
    "        self.labels = []\n",
    "        self.gloss_to_indices = {}\n",
    "\n",
    "        with open(label_map_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            self.label_map = json.load(f)\n",
    "\n",
    "        for gloss_name in sorted(os.listdir(root_dir)):\n",
    "            gloss_path = os.path.join(root_dir, gloss_name)\n",
    "            if not os.path.isdir(gloss_path):\n",
    "                continue\n",
    "\n",
    "            if gloss_name not in self.label_map:\n",
    "                raise ValueError(f\"Gloss '{gloss_name}' not found in label_map.json\")\n",
    "\n",
    "            gloss_id = int(self.label_map[gloss_name])\n",
    "\n",
    "            for fname in os.listdir(gloss_path):\n",
    "                if not fname.endswith(\".npz\"):\n",
    "                    continue\n",
    "\n",
    "                fpath = os.path.join(gloss_path, fname)\n",
    "                idx = len(self.samples)\n",
    "\n",
    "                self.samples.append(fpath)\n",
    "                self.labels.append(gloss_id)\n",
    "\n",
    "                if gloss_id not in self.gloss_to_indices:\n",
    "                    self.gloss_to_indices[gloss_id] = []\n",
    "                self.gloss_to_indices[gloss_id].append(idx)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        npz = np.load(self.samples[idx])\n",
    "        x = npz[\"sequence\"]\n",
    "        y = self.labels[idx]\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83913188",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T15:46:27.948596Z",
     "iopub.status.busy": "2026-01-25T15:46:27.948048Z",
     "iopub.status.idle": "2026-01-25T15:46:27.954394Z",
     "shell.execute_reply": "2026-01-25T15:46:27.953927Z"
    },
    "papermill": {
     "duration": 0.011361,
     "end_time": "2026-01-25T15:46:27.955669",
     "exception": false,
     "start_time": "2026-01-25T15:46:27.944308",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PKSampler(Sampler):\n",
    "    def __init__(self, gloss_to_indices, P=32, K=8, steps_per_epoch=1000):\n",
    "        self.gloss_to_indices = gloss_to_indices\n",
    "        self.P = P\n",
    "        self.K = K\n",
    "        self.steps_per_epoch = steps_per_epoch\n",
    "\n",
    "        self.ptr = {}\n",
    "        self.buffers = {}\n",
    "\n",
    "        # Chỉ giữ gloss đủ K sample\n",
    "        self.gloss_ids = [\n",
    "            g for g, idxs in gloss_to_indices.items()\n",
    "            if len(idxs) >= K\n",
    "        ]\n",
    "\n",
    "        if len(self.gloss_ids) < P:\n",
    "            raise ValueError(\n",
    "                f\"Not enough glosses with >=K samples: \"\n",
    "                f\"{len(self.gloss_ids)} < P={P}\"\n",
    "            )\n",
    "\n",
    "        for g in self.gloss_ids:\n",
    "            idxs = gloss_to_indices[g].copy()\n",
    "            random.shuffle(idxs)\n",
    "            self.buffers[g] = idxs\n",
    "            self.ptr[g] = 0\n",
    "\n",
    "    def __len__(self):\n",
    "        # pseudo-length (steps per epoch)\n",
    "        return self.steps_per_epoch\n",
    "\n",
    "    def __iter__(self):\n",
    "        for _ in range(self.steps_per_epoch):\n",
    "            batch = []\n",
    "\n",
    "            gloss_batch = random.sample(self.gloss_ids, self.P)\n",
    "\n",
    "            for g in gloss_batch:\n",
    "                idxs = self.buffers[g]\n",
    "                p = self.ptr[g]\n",
    "\n",
    "                if p + self.K > len(idxs):\n",
    "                    random.shuffle(idxs)\n",
    "                    p = 0\n",
    "\n",
    "                batch.extend(idxs[p:p + self.K])\n",
    "                self.ptr[g] = p + self.K\n",
    "\n",
    "            yield batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97d5590f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T15:46:27.962264Z",
     "iopub.status.busy": "2026-01-25T15:46:27.962044Z",
     "iopub.status.idle": "2026-01-25T15:47:29.350501Z",
     "shell.execute_reply": "2026-01-25T15:47:29.349908Z"
    },
    "papermill": {
     "duration": 61.393883,
     "end_time": "2026-01-25T15:47:29.352323",
     "exception": false,
     "start_time": "2026-01-25T15:46:27.958440",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "label_map_path = \"/kaggle/input/vsl-vietnamese-sign-languages/Processed/label_map.json\"\n",
    "train_root = \"/kaggle/input/vsl-vietnamese-sign-languages/Processed/train\"\n",
    "val_root = \"/kaggle/input/vsl-vietnamese-sign-languages/Processed/val\"\n",
    "test_root = \"/kaggle/input/vsl-vietnamese-sign-languages/Processed/test\"\n",
    "\n",
    "train_ds = VSLDataset(train_root, label_map_path)\n",
    "val_ds = VSLDataset(val_root, label_map_path)\n",
    "test_ds = VSLDataset(test_root, label_map_path)\n",
    "\n",
    "sampler = PKSampler(\n",
    "    gloss_to_indices=train_ds.gloss_to_indices,\n",
    "    P=32, # Số gloss mỗi step\n",
    "    K=4, # Số sequence mỗi step\n",
    "    steps_per_epoch=1000 # Số step mỗi epoch\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_sampler=sampler,\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_ds,\n",
    "    batch_size=256,\n",
    "    num_workers=4,\n",
    "    pin_memory=True \n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    val_ds,\n",
    "    batch_size=256,\n",
    "    num_workers=4,\n",
    "    pin_memory=True \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02a313f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T15:47:29.359751Z",
     "iopub.status.busy": "2026-01-25T15:47:29.359532Z",
     "iopub.status.idle": "2026-01-25T15:47:29.375376Z",
     "shell.execute_reply": "2026-01-25T15:47:29.374681Z"
    },
    "papermill": {
     "duration": 0.021256,
     "end_time": "2026-01-25T15:47:29.376760",
     "exception": false,
     "start_time": "2026-01-25T15:47:29.355504",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mp_holistic = mp.solutions.holistic\n",
    "\n",
    "N_UPPER_BODY_POSE_LANDMARKS = 25\n",
    "N_HAND_LANDMARKS = 21\n",
    "N_TOTAL_LANDMARKS = 67\n",
    "\n",
    "\n",
    "def build_adjacency(self_loop=True):\n",
    "    A = torch.zeros(N_TOTAL_LANDMARKS, N_TOTAL_LANDMARKS)\n",
    "    for i, j in mp_holistic.POSE_CONNECTIONS:\n",
    "        if i < N_UPPER_BODY_POSE_LANDMARKS and j < N_UPPER_BODY_POSE_LANDMARKS:\n",
    "            A[i, j] = 1\n",
    "            A[j, i] = 1\n",
    "\n",
    "    LEFT_HAND_OFFSET = N_UPPER_BODY_POSE_LANDMARKS\n",
    "    for i, j in mp_holistic.HAND_CONNECTIONS:\n",
    "        A[LEFT_HAND_OFFSET + i, LEFT_HAND_OFFSET + j] = 1\n",
    "        A[LEFT_HAND_OFFSET + j, LEFT_HAND_OFFSET + i] = 1\n",
    "\n",
    "    RIGHT_HAND_OFFSET = N_UPPER_BODY_POSE_LANDMARKS + N_HAND_LANDMARKS\n",
    "    for i, j in mp_holistic.HAND_CONNECTIONS:\n",
    "        A[RIGHT_HAND_OFFSET + i, RIGHT_HAND_OFFSET + j] = 1\n",
    "        A[RIGHT_HAND_OFFSET + j, RIGHT_HAND_OFFSET + i] = 1\n",
    "\n",
    "    POSE_LEFT_WRIST = 15\n",
    "    POSE_RIGHT_WRIST = 16\n",
    "\n",
    "    LEFT_HAND_WRIST = LEFT_HAND_OFFSET + 0\n",
    "    RIGHT_HAND_WRIST = RIGHT_HAND_OFFSET + 0\n",
    "\n",
    "    A[POSE_LEFT_WRIST, LEFT_HAND_WRIST] = 1\n",
    "    A[LEFT_HAND_WRIST, POSE_LEFT_WRIST] = 1\n",
    "\n",
    "    A[POSE_RIGHT_WRIST, RIGHT_HAND_WRIST] = 1\n",
    "    A[RIGHT_HAND_WRIST, POSE_RIGHT_WRIST] = 1\n",
    "\n",
    "    if self_loop:\n",
    "        A += torch.eye(N_TOTAL_LANDMARKS)\n",
    "\n",
    "    A = A / A.sum(dim=1, keepdim=True)\n",
    "\n",
    "    return A\n",
    "\n",
    "def build_bone_input(x):\n",
    "    \"\"\"\n",
    "    x: (B, T, V, C)\n",
    "    \"\"\"\n",
    "    B, T, V, C = x.shape\n",
    "    bone = torch.zeros_like(x)\n",
    "\n",
    "    for i, j in mp_holistic.POSE_CONNECTIONS:\n",
    "        if i < N_UPPER_BODY_POSE_LANDMARKS and j < N_UPPER_BODY_POSE_LANDMARKS:\n",
    "            bone[:, :, i] = x[:, :, j] - x[:, :, i]\n",
    "\n",
    "    LEFT_HAND_OFFSET = N_UPPER_BODY_POSE_LANDMARKS\n",
    "    RIGHT_HAND_OFFSET = N_UPPER_BODY_POSE_LANDMARKS + N_HAND_LANDMARKS\n",
    "\n",
    "    for i, j in mp_holistic.HAND_CONNECTIONS:\n",
    "        bone[:, :, LEFT_HAND_OFFSET + i] = \\\n",
    "            x[:, :, LEFT_HAND_OFFSET + j] - x[:, :, LEFT_HAND_OFFSET + i]\n",
    "\n",
    "        bone[:, :, RIGHT_HAND_OFFSET + i] = \\\n",
    "            x[:, :, RIGHT_HAND_OFFSET + j] - x[:, :, RIGHT_HAND_OFFSET + i]\n",
    "\n",
    "    return bone\n",
    "    \n",
    "class AGCNBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, A, kernel_size=9):\n",
    "        super().__init__()\n",
    "        V = A.size(0)\n",
    "        self.register_buffer(\"A_static\", A)\n",
    "\n",
    "        # adaptive adjacency\n",
    "        self.A_adaptive = nn.Parameter(torch.zeros(V, V))\n",
    "\n",
    "        self.gcn = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "        padding = ((kernel_size - 1) // 2, 0)\n",
    "        self.tcn = nn.Conv2d(\n",
    "            out_channels, out_channels,\n",
    "            kernel_size=(kernel_size, 1),\n",
    "            padding=padding\n",
    "        )\n",
    "\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, C, T, V)\n",
    "        A = self.A_static + self.A_adaptive\n",
    "\n",
    "        x = torch.einsum(\"vw,bctw->bctv\", A, x)\n",
    "        x = self.gcn(x)\n",
    "        x = self.tcn(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "class VSL_2sAGCN(nn.Module):\n",
    "    def __init__(self, in_dim=3, hidden_dim=256, emb_dim=256):\n",
    "        super().__init__()\n",
    "        A = build_adjacency()\n",
    "\n",
    "        # Joint stream\n",
    "        self.joint1 = AGCNBlock(in_dim, hidden_dim, A)\n",
    "        self.joint2 = AGCNBlock(hidden_dim, hidden_dim, A)\n",
    "\n",
    "        # Bone stream\n",
    "        self.bone1 = AGCNBlock(in_dim, hidden_dim, A)\n",
    "        self.bone2 = AGCNBlock(hidden_dim, hidden_dim, A)\n",
    "\n",
    "        self.fc = nn.Linear(hidden_dim * 2, emb_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: (B, T, V*C)\n",
    "        \"\"\"\n",
    "        B, T, _ = x.shape\n",
    "        x = x.view(B, T, N_TOTAL_LANDMARKS, 3)\n",
    "\n",
    "        bone = build_bone_input(x)\n",
    "\n",
    "        # to (B, C, T, V)\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "        bone = bone.permute(0, 3, 1, 2)\n",
    "\n",
    "        # joint stream\n",
    "        x = self.joint1(x)\n",
    "        x = self.joint2(x)\n",
    "        x = x.mean(dim=[2, 3])  # (B, hidden)\n",
    "\n",
    "        # bone stream\n",
    "        b = self.bone1(bone)\n",
    "        b = self.bone2(b)\n",
    "        b = b.mean(dim=[2, 3])\n",
    "\n",
    "        # fuse\n",
    "        feat = torch.cat([x, b], dim=1)\n",
    "        emb = self.fc(feat)\n",
    "        emb = F.normalize(emb, dim=1)\n",
    "        return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72f64f3e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T15:47:29.383607Z",
     "iopub.status.busy": "2026-01-25T15:47:29.383387Z",
     "iopub.status.idle": "2026-01-25T15:47:29.388908Z",
     "shell.execute_reply": "2026-01-25T15:47:29.388251Z"
    },
    "papermill": {
     "duration": 0.010541,
     "end_time": "2026-01-25T15:47:29.390266",
     "exception": false,
     "start_time": "2026-01-25T15:47:29.379725",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SupConLoss(nn.Module):\n",
    "    def __init__(self, temperature=0.07):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def forward(self, features, labels):\n",
    "        features = F.normalize(features, dim=1)\n",
    "        labels = labels.view(-1, 1)\n",
    "\n",
    "        mask = torch.eq(labels, labels.T).float().to(features.device)\n",
    "\n",
    "        logits = torch.matmul(features, features.T) / self.temperature\n",
    "        logits = logits - logits.max(dim=1, keepdim=True)[0].detach()\n",
    "\n",
    "        logits_mask = torch.ones_like(mask)\n",
    "        logits_mask.fill_diagonal_(0)\n",
    "        mask = mask * logits_mask\n",
    "\n",
    "        exp_logits = torch.exp(logits) * logits_mask\n",
    "        log_prob = logits - torch.log(exp_logits.sum(1, keepdim=True) + 1e-8)\n",
    "\n",
    "        mean_log_prob_pos = (mask * log_prob).sum(1) / (mask.sum(1) + 1e-8)\n",
    "        loss = -mean_log_prob_pos.mean()\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "059d33b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T15:47:29.396690Z",
     "iopub.status.busy": "2026-01-25T15:47:29.396428Z",
     "iopub.status.idle": "2026-01-25T15:47:29.402844Z",
     "shell.execute_reply": "2026-01-25T15:47:29.402171Z"
    },
    "papermill": {
     "duration": 0.011164,
     "end_time": "2026-01-25T15:47:29.404143",
     "exception": false,
     "start_time": "2026-01-25T15:47:29.392979",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def eval_recall_at_k_faiss(\n",
    "    model,\n",
    "    val_loader,\n",
    "    device,\n",
    "    Ks=(1, 5)\n",
    "):\n",
    "    model.eval()\n",
    "\n",
    "    # ===== 1. Extract embeddings =====\n",
    "    all_embs = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in tqdm(val_loader, desc=\"Extract val emb\", leave=False):\n",
    "            x = x.to(device).float()\n",
    "            emb = model(x)                 # (B, D)\n",
    "            emb = F.normalize(emb, dim=1)  # cosine\n",
    "\n",
    "            all_embs.append(emb.cpu())\n",
    "            all_labels.append(y.cpu())\n",
    "\n",
    "    all_embs = torch.cat(all_embs, dim=0)      # (N, D)\n",
    "    all_labels = torch.cat(all_labels, dim=0)  # (N,)\n",
    "\n",
    "    # ===== 2. FAISS index =====\n",
    "    emb_np = all_embs.numpy().astype(\"float32\")\n",
    "    labels_np = all_labels.numpy()\n",
    "\n",
    "    dim = emb_np.shape[1]\n",
    "\n",
    "    index = faiss.IndexFlatIP(dim)  # Inner Product\n",
    "    index.add(emb_np)               # N vectors\n",
    "\n",
    "    # ===== 3. Search =====\n",
    "    max_k = max(Ks) + 1  # +1 để bỏ self-match\n",
    "    D, I = index.search(emb_np, max_k)\n",
    "\n",
    "    recalls = {}\n",
    "    for K in Ks:\n",
    "        correct = 0\n",
    "        for i in range(len(I)):\n",
    "            # bỏ chính nó\n",
    "            neighbors = I[i][I[i] != i][:K]\n",
    "            if labels_np[i] in labels_np[neighbors]:\n",
    "                correct += 1\n",
    "\n",
    "        recalls[K] = correct / len(I)\n",
    "\n",
    "    return recalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2d1d7fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T15:47:29.411105Z",
     "iopub.status.busy": "2026-01-25T15:47:29.410511Z",
     "iopub.status.idle": "2026-01-25T15:47:34.333152Z",
     "shell.execute_reply": "2026-01-25T15:47:34.332351Z"
    },
    "papermill": {
     "duration": 4.927703,
     "end_time": "2026-01-25T15:47:34.334677",
     "exception": false,
     "start_time": "2026-01-25T15:47:29.406974",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24/2984174528.py:16: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler(enabled=use_amp)\n"
     ]
    }
   ],
   "source": [
    "model = VSL_2sAGCN(\n",
    "    in_dim=3,\n",
    "    hidden_dim=256,\n",
    "    emb_dim=256\n",
    ")\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = SupConLoss(temperature=0.07)\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(), lr=1e-3, weight_decay=1e-4\n",
    ")\n",
    "\n",
    "use_amp = (device == \"cuda\")\n",
    "scaler = GradScaler(enabled=use_amp)\n",
    "\n",
    "epochs = 5\n",
    "eval_interval = 1\n",
    "\n",
    "save_dir = \"./checkpoints\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "best_recall1 = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa0f14b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T15:47:34.342459Z",
     "iopub.status.busy": "2026-01-25T15:47:34.341697Z",
     "iopub.status.idle": "2026-01-25T18:00:22.330537Z",
     "shell.execute_reply": "2026-01-25T18:00:22.329692Z"
    },
    "papermill": {
     "duration": 7967.994444,
     "end_time": "2026-01-25T18:00:22.332197",
     "exception": false,
     "start_time": "2026-01-25T15:47:34.337753",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:   0%|                                                                               | 0/1000 [00:00<?, ?it/s]/tmp/ipykernel_24/883657663.py:46: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=use_amp):\n",
      "Epoch 1/5: 100%|█████████████████████████████████████████████| 1000/1000 [25:40<00:00,  1.54s/it, loss=1.4526, lr=0.001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: train_loss=1.6101, lr=1.00e-03, time=1540.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Valid Epoch 1 | R@1: 99.40% | \n",
      "Saved BEST encoder (Recall@1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|█████████████████████████████████████████████| 1000/1000 [25:35<00:00,  1.54s/it, loss=1.4145, lr=0.001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2: train_loss=1.4670, lr=1.00e-03, time=1535.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Valid Epoch 2 | R@1: 99.70% | \n",
      "Saved BEST encoder (Recall@1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|█████████████████████████████████████████████| 1000/1000 [25:35<00:00,  1.54s/it, loss=1.3200, lr=0.001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3: train_loss=1.4174, lr=1.00e-03, time=1535.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Valid Epoch 3 | R@1: 99.69% | \n",
      "⏸ No Recall@1 improvement (1/6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|█████████████████████████████████████████████| 1000/1000 [25:35<00:00,  1.54s/it, loss=1.1678, lr=0.001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4: train_loss=1.3798, lr=1.00e-03, time=1535.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Valid Epoch 4 | R@1: 99.76% | \n",
      "Saved BEST encoder (Recall@1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|█████████████████████████████████████████████| 1000/1000 [25:35<00:00,  1.54s/it, loss=1.2715, lr=0.001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5: train_loss=1.3568, lr=1.00e-03, time=1535.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Valid Epoch 5 | R@1: 99.74% | \n",
      "⏸ No Recall@1 improvement (1/6)\n",
      "Encoder training finished\n"
     ]
    }
   ],
   "source": [
    "lr_patience = 2\n",
    "early_stop_patience = 6\n",
    "best_recall1 = 0.0\n",
    "no_improve_count = 0\n",
    "\n",
    "log_path = os.path.join(save_dir, \"train_log.csv\")\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode=\"max\",\n",
    "    factor=0.3,\n",
    "    patience=lr_patience,\n",
    "    min_lr=1e-6,\n",
    ")\n",
    "\n",
    "\n",
    "if not os.path.exists(log_path):\n",
    "    with open(log_path, \"w\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\n",
    "            \"epoch\",\n",
    "            \"train_loss\",\n",
    "            \"recall@1\",\n",
    "            \"lr\",\n",
    "            \"epoch_time_sec\"\n",
    "        ])\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    start_time = time.time()\n",
    "\n",
    "    pbar = tqdm(\n",
    "        train_loader,\n",
    "        desc=f\"Epoch {epoch+1}/{epochs}\",\n",
    "        ncols=120\n",
    "    )\n",
    "\n",
    "    for step, (x, y) in enumerate(pbar):\n",
    "        x = x.to(device).float()\n",
    "        y = y.to(device).long()\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        with autocast(enabled=use_amp):\n",
    "            emb = model(x)\n",
    "            loss = criterion(emb, y)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        pbar.set_postfix({\n",
    "            \"loss\": f\"{loss.item():.4f}\",\n",
    "            \"lr\": optimizer.param_groups[0][\"lr\"]\n",
    "        })\n",
    "\n",
    "    avg_loss = epoch_loss / (step + 1)\n",
    "    epoch_time = time.time() - start_time\n",
    "    current_lr = optimizer.param_groups[0][\"lr\"]\n",
    "\n",
    "    print(\n",
    "        f\"\\nEpoch {epoch+1}: \"\n",
    "        f\"train_loss={avg_loss:.4f}, \"\n",
    "        f\"lr={current_lr:.2e}, \"\n",
    "        f\"time={epoch_time:.1f}s\"\n",
    "    )\n",
    "\n",
    "    # -------- SAVE LAST --------\n",
    "    torch.save(\n",
    "        {\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"model\": model.state_dict(),\n",
    "            \"optimizer\": optimizer.state_dict(),\n",
    "        },\n",
    "        f\"{save_dir}/last_encoder.pt\"\n",
    "    )\n",
    "\n",
    "    recall1 = None\n",
    "\n",
    "    if (epoch + 1) % eval_interval == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            recalls = eval_recall_at_k_faiss(\n",
    "                model,\n",
    "                val_loader,\n",
    "                device,\n",
    "                Ks=(1, 5)\n",
    "            )\n",
    "\n",
    "        recall1 = recalls[1]\n",
    "\n",
    "        print(\n",
    "            f\"\\n Valid Epoch {epoch+1} | \"\n",
    "            f\"R@1: {recall1*100:.2f}% | \"\n",
    "        )\n",
    "\n",
    "        scheduler.step(recall1)\n",
    "\n",
    "        if recall1 > best_recall1:\n",
    "            best_recall1 = recall1\n",
    "            no_improve_count = 0\n",
    "\n",
    "            torch.save(\n",
    "                model.state_dict(),\n",
    "                f\"{save_dir}/best_encoder.pt\"\n",
    "            )\n",
    "            print(\"Saved BEST encoder (Recall@1)\")\n",
    "\n",
    "        else:\n",
    "            no_improve_count += 1\n",
    "            print(\n",
    "                f\"⏸ No Recall@1 improvement \"\n",
    "                f\"({no_improve_count}/{early_stop_patience})\"\n",
    "            )\n",
    "\n",
    "    with open(log_path, \"a\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\n",
    "            epoch + 1,\n",
    "            round(avg_loss, 6),\n",
    "            None if recall1 is None else round(recall1, 6),\n",
    "            f\"{current_lr:.2e}\",\n",
    "            round(epoch_time, 2)\n",
    "        ])\n",
    "\n",
    "    if no_improve_count >= early_stop_patience:\n",
    "        print(\n",
    "            f\"\\nEarly stopping at epoch {epoch+1} \"\n",
    "            f\"(no Recall@1 improvement for \"\n",
    "            f\"{early_stop_patience} evals)\"\n",
    "        )\n",
    "        break\n",
    "\n",
    "print(\"Encoder training finished\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9951086",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T18:00:23.209419Z",
     "iopub.status.busy": "2026-01-25T18:00:23.208718Z",
     "iopub.status.idle": "2026-01-25T18:01:20.181052Z",
     "shell.execute_reply": "2026-01-25T18:01:20.180141Z"
    },
    "papermill": {
     "duration": 57.356102,
     "end_time": "2026-01-25T18:01:20.182676",
     "exception": false,
     "start_time": "2026-01-25T18:00:22.826574",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Valid | R@1: 99.76% | R@5: 99.82%\n"
     ]
    }
   ],
   "source": [
    "model_dir = \"./checkpoints\"\n",
    "\n",
    "model = VSL_2sAGCN(\n",
    "    in_dim=3,\n",
    "    hidden_dim=256,\n",
    "    emb_dim=256\n",
    ")\n",
    "\n",
    "model.to(\"cuda\")\n",
    "\n",
    "ckpt_path = f\"{model_dir}/best_encoder.pt\"\n",
    "model.load_state_dict(torch.load(ckpt_path, map_location=device))\n",
    "\n",
    "recalls = eval_recall_at_k_faiss(\n",
    "            model,\n",
    "            test_loader,\n",
    "            device,\n",
    "            Ks=(1, 5)\n",
    "        )\n",
    "\n",
    "recall1 = recalls[1]\n",
    "recall5 = recalls[5]\n",
    "\n",
    "print(\n",
    "    f\"\\n Valid | \"\n",
    "    f\"R@1: {recall1*100:.2f}% | \"\n",
    "    f\"R@5: {recall5*100:.2f}%\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f48454f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T18:01:21.041236Z",
     "iopub.status.busy": "2026-01-25T18:01:21.040920Z",
     "iopub.status.idle": "2026-01-25T18:01:21.735451Z",
     "shell.execute_reply": "2026-01-25T18:01:21.734452Z"
    },
    "papermill": {
     "duration": 1.082553,
     "end_time": "2026-01-25T18:01:21.737241",
     "exception": false,
     "start_time": "2026-01-25T18:01:20.654688",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: checkpoints/best_encoder.pt (deflated 8%)\r\n"
     ]
    }
   ],
   "source": [
    "!zip best.zip ./checkpoints/best_encoder.pt"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 9273717,
     "sourceId": 14603584,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31260,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 8126.947708,
   "end_time": "2026-01-25T18:01:25.583287",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-01-25T15:45:58.635579",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
