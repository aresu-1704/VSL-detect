{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3655a9e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T17:07:19.584349Z",
     "iopub.status.busy": "2026-01-25T17:07:19.583697Z",
     "iopub.status.idle": "2026-01-25T17:07:27.364822Z",
     "shell.execute_reply": "2026-01-25T17:07:27.363880Z"
    },
    "papermill": {
     "duration": 7.78684,
     "end_time": "2026-01-25T17:07:27.366303",
     "exception": false,
     "start_time": "2026-01-25T17:07:19.579463",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.7/35.7 MB\u001b[0m \u001b[31m55.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.8/23.8 MB\u001b[0m \u001b[31m94.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "google-adk 1.22.1 requires google-cloud-bigquery-storage>=2.0.0, which is not installed.\r\n",
      "bigframes 2.26.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\r\n",
      "a2a-sdk 0.3.22 requires protobuf>=5.29.5, but you have protobuf 4.25.8 which is incompatible.\r\n",
      "opentelemetry-proto 1.37.0 requires protobuf<7.0,>=5.0, but you have protobuf 4.25.8 which is incompatible.\r\n",
      "ydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 4.25.8 which is incompatible.\r\n",
      "bigframes 2.26.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\r\n",
      "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.8 which is incompatible.\r\n",
      "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.10.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q faiss-cpu mediapipe==0.10.14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52ddb41f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T17:07:27.373973Z",
     "iopub.status.busy": "2026-01-25T17:07:27.373309Z",
     "iopub.status.idle": "2026-01-25T17:07:27.377032Z",
     "shell.execute_reply": "2026-01-25T17:07:27.376500Z"
    },
    "papermill": {
     "duration": 0.008925,
     "end_time": "2026-01-25T17:07:27.378334",
     "exception": false,
     "start_time": "2026-01-25T17:07:27.369409",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a52541e3",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2026-01-25T17:07:27.384960Z",
     "iopub.status.busy": "2026-01-25T17:07:27.384502Z",
     "iopub.status.idle": "2026-01-25T17:07:46.514552Z",
     "shell.execute_reply": "2026-01-25T17:07:46.513929Z"
    },
    "papermill": {
     "duration": 19.13519,
     "end_time": "2026-01-25T17:07:46.516250",
     "exception": false,
     "start_time": "2026-01-25T17:07:27.381060",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-25 17:07:33.276893: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1769360853.482738      23 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1769360853.541503      23 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1769360854.012573      23 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1769360854.012612      23 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1769360854.012615      23 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1769360854.012617      23 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import json\n",
    "from torch.utils.data import Dataset, Sampler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import faiss\n",
    "import csv\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b0abc58",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T17:07:46.523595Z",
     "iopub.status.busy": "2026-01-25T17:07:46.523169Z",
     "iopub.status.idle": "2026-01-25T17:07:46.531081Z",
     "shell.execute_reply": "2026-01-25T17:07:46.530489Z"
    },
    "papermill": {
     "duration": 0.013208,
     "end_time": "2026-01-25T17:07:46.532465",
     "exception": false,
     "start_time": "2026-01-25T17:07:46.519257",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class VSLDataset(Dataset):\n",
    "    def __init__(self, root_dir, label_map_path):\n",
    "        self.samples = []\n",
    "        self.labels = []\n",
    "        self.gloss_to_indices = {}\n",
    "\n",
    "        with open(label_map_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            self.label_map = json.load(f)\n",
    "\n",
    "        for gloss_name in sorted(os.listdir(root_dir)):\n",
    "            gloss_path = os.path.join(root_dir, gloss_name)\n",
    "            if not os.path.isdir(gloss_path):\n",
    "                continue\n",
    "\n",
    "            if gloss_name not in self.label_map:\n",
    "                raise ValueError(f\"Gloss '{gloss_name}' not found in label_map.json\")\n",
    "\n",
    "            gloss_id = int(self.label_map[gloss_name])\n",
    "\n",
    "            for fname in os.listdir(gloss_path):\n",
    "                if not fname.endswith(\".npz\"):\n",
    "                    continue\n",
    "\n",
    "                fpath = os.path.join(gloss_path, fname)\n",
    "                idx = len(self.samples)\n",
    "\n",
    "                self.samples.append(fpath)\n",
    "                self.labels.append(gloss_id)\n",
    "\n",
    "                if gloss_id not in self.gloss_to_indices:\n",
    "                    self.gloss_to_indices[gloss_id] = []\n",
    "                self.gloss_to_indices[gloss_id].append(idx)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        npz = np.load(self.samples[idx])\n",
    "        x = npz[\"sequence\"]\n",
    "        y = self.labels[idx]\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54fa9f50",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T17:07:46.539092Z",
     "iopub.status.busy": "2026-01-25T17:07:46.538867Z",
     "iopub.status.idle": "2026-01-25T17:07:46.545383Z",
     "shell.execute_reply": "2026-01-25T17:07:46.544857Z"
    },
    "papermill": {
     "duration": 0.0114,
     "end_time": "2026-01-25T17:07:46.546653",
     "exception": false,
     "start_time": "2026-01-25T17:07:46.535253",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PKSampler(Sampler):\n",
    "    def __init__(self, gloss_to_indices, P=32, K=8, steps_per_epoch=1000):\n",
    "        self.gloss_to_indices = gloss_to_indices\n",
    "        self.P = P\n",
    "        self.K = K\n",
    "        self.steps_per_epoch = steps_per_epoch\n",
    "\n",
    "        self.ptr = {}\n",
    "        self.buffers = {}\n",
    "\n",
    "        # Chỉ giữ gloss đủ K sample\n",
    "        self.gloss_ids = [\n",
    "            g for g, idxs in gloss_to_indices.items()\n",
    "            if len(idxs) >= K\n",
    "        ]\n",
    "\n",
    "        if len(self.gloss_ids) < P:\n",
    "            raise ValueError(\n",
    "                f\"Not enough glosses with >=K samples: \"\n",
    "                f\"{len(self.gloss_ids)} < P={P}\"\n",
    "            )\n",
    "\n",
    "        for g in self.gloss_ids:\n",
    "            idxs = gloss_to_indices[g].copy()\n",
    "            random.shuffle(idxs)\n",
    "            self.buffers[g] = idxs\n",
    "            self.ptr[g] = 0\n",
    "\n",
    "    def __len__(self):\n",
    "        # pseudo-length (steps per epoch)\n",
    "        return self.steps_per_epoch\n",
    "\n",
    "    def __iter__(self):\n",
    "        for _ in range(self.steps_per_epoch):\n",
    "            batch = []\n",
    "\n",
    "            gloss_batch = random.sample(self.gloss_ids, self.P)\n",
    "\n",
    "            for g in gloss_batch:\n",
    "                idxs = self.buffers[g]\n",
    "                p = self.ptr[g]\n",
    "\n",
    "                if p + self.K > len(idxs):\n",
    "                    random.shuffle(idxs)\n",
    "                    p = 0\n",
    "\n",
    "                batch.extend(idxs[p:p + self.K])\n",
    "                self.ptr[g] = p + self.K\n",
    "\n",
    "            yield batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d063c7ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T17:07:46.553368Z",
     "iopub.status.busy": "2026-01-25T17:07:46.553141Z",
     "iopub.status.idle": "2026-01-25T17:08:49.694485Z",
     "shell.execute_reply": "2026-01-25T17:08:49.693863Z"
    },
    "papermill": {
     "duration": 63.146767,
     "end_time": "2026-01-25T17:08:49.696225",
     "exception": false,
     "start_time": "2026-01-25T17:07:46.549458",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "label_map_path = \"/kaggle/input/vsl-vietnamese-sign-languages/Processed/label_map.json\"\n",
    "train_root = \"/kaggle/input/vsl-vietnamese-sign-languages/Processed/train\"\n",
    "val_root = \"/kaggle/input/vsl-vietnamese-sign-languages/Processed/val\"\n",
    "test_root = \"/kaggle/input/vsl-vietnamese-sign-languages/Processed/test\"\n",
    "\n",
    "train_ds = VSLDataset(train_root, label_map_path)\n",
    "val_ds = VSLDataset(val_root, label_map_path)\n",
    "test_ds = VSLDataset(test_root, label_map_path)\n",
    "\n",
    "sampler = PKSampler(\n",
    "    gloss_to_indices=train_ds.gloss_to_indices,\n",
    "    P=32, # Số gloss mỗi step\n",
    "    K=4, # Số sequence mỗi step\n",
    "    steps_per_epoch=1000 # Số step mỗi epoch\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_sampler=sampler,\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_ds,\n",
    "    batch_size=256,\n",
    "    num_workers=4,\n",
    "    pin_memory=True \n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    val_ds,\n",
    "    batch_size=256,\n",
    "    num_workers=4,\n",
    "    pin_memory=True \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33d8c08f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T17:08:49.703574Z",
     "iopub.status.busy": "2026-01-25T17:08:49.703330Z",
     "iopub.status.idle": "2026-01-25T17:08:49.708775Z",
     "shell.execute_reply": "2026-01-25T17:08:49.708249Z"
    },
    "papermill": {
     "duration": 0.010686,
     "end_time": "2026-01-25T17:08:49.710137",
     "exception": false,
     "start_time": "2026-01-25T17:08:49.699451",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class VSL_BiLSTM_Encoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim=201,\n",
    "        hidden_dim=256,\n",
    "        num_layers=2,\n",
    "        emb_dim=256,\n",
    "        dropout=0.2\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=True,\n",
    "            dropout=dropout if num_layers > 1 else 0.0\n",
    "        )\n",
    "\n",
    "        self.proj = nn.Linear(hidden_dim * 2, emb_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: (B, T, 201)\n",
    "        \"\"\"\n",
    "        # LSTM\n",
    "        out, _ = self.lstm(x)     # (B, T, 2*hidden)\n",
    "\n",
    "        # Temporal pooling (mean)\n",
    "        out = out.mean(dim=1)     # (B, 2*hidden)\n",
    "\n",
    "        # Projection\n",
    "        emb = self.proj(out)      # (B, emb_dim)\n",
    "        emb = F.normalize(emb, dim=1)\n",
    "\n",
    "        return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "feb51a51",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T17:08:49.716733Z",
     "iopub.status.busy": "2026-01-25T17:08:49.716517Z",
     "iopub.status.idle": "2026-01-25T17:08:49.722186Z",
     "shell.execute_reply": "2026-01-25T17:08:49.721596Z"
    },
    "papermill": {
     "duration": 0.010619,
     "end_time": "2026-01-25T17:08:49.723566",
     "exception": false,
     "start_time": "2026-01-25T17:08:49.712947",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SupConLoss(nn.Module):\n",
    "    def __init__(self, temperature=0.07):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def forward(self, features, labels):\n",
    "        features = F.normalize(features, dim=1)\n",
    "        labels = labels.view(-1, 1)\n",
    "\n",
    "        mask = torch.eq(labels, labels.T).float().to(features.device)\n",
    "\n",
    "        logits = torch.matmul(features, features.T) / self.temperature\n",
    "        logits = logits - logits.max(dim=1, keepdim=True)[0].detach()\n",
    "\n",
    "        logits_mask = torch.ones_like(mask)\n",
    "        logits_mask.fill_diagonal_(0)\n",
    "        mask = mask * logits_mask\n",
    "\n",
    "        exp_logits = torch.exp(logits) * logits_mask\n",
    "        log_prob = logits - torch.log(exp_logits.sum(1, keepdim=True) + 1e-8)\n",
    "\n",
    "        mean_log_prob_pos = (mask * log_prob).sum(1) / (mask.sum(1) + 1e-8)\n",
    "        loss = -mean_log_prob_pos.mean()\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2653727a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T17:08:49.730271Z",
     "iopub.status.busy": "2026-01-25T17:08:49.730044Z",
     "iopub.status.idle": "2026-01-25T17:08:49.736379Z",
     "shell.execute_reply": "2026-01-25T17:08:49.735856Z"
    },
    "papermill": {
     "duration": 0.011201,
     "end_time": "2026-01-25T17:08:49.737602",
     "exception": false,
     "start_time": "2026-01-25T17:08:49.726401",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def eval_recall_at_k_faiss(\n",
    "    model,\n",
    "    val_loader,\n",
    "    device,\n",
    "    Ks=(1, 5)\n",
    "):\n",
    "    model.eval()\n",
    "\n",
    "    # ===== 1. Extract embeddings =====\n",
    "    all_embs = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in tqdm(val_loader, desc=\"Extract val emb\", leave=False):\n",
    "            x = x.to(device).float()\n",
    "            emb = model(x)                 # (B, D)\n",
    "            emb = F.normalize(emb, dim=1)  # cosine\n",
    "\n",
    "            all_embs.append(emb.cpu())\n",
    "            all_labels.append(y.cpu())\n",
    "\n",
    "    all_embs = torch.cat(all_embs, dim=0)      # (N, D)\n",
    "    all_labels = torch.cat(all_labels, dim=0)  # (N,)\n",
    "\n",
    "    # ===== 2. FAISS index =====\n",
    "    emb_np = all_embs.numpy().astype(\"float32\")\n",
    "    labels_np = all_labels.numpy()\n",
    "\n",
    "    dim = emb_np.shape[1]\n",
    "\n",
    "    index = faiss.IndexFlatIP(dim)  # Inner Product\n",
    "    index.add(emb_np)               # N vectors\n",
    "\n",
    "    # ===== 3. Search =====\n",
    "    max_k = max(Ks) + 1  # +1 để bỏ self-match\n",
    "    D, I = index.search(emb_np, max_k)\n",
    "\n",
    "    recalls = {}\n",
    "    for K in Ks:\n",
    "        correct = 0\n",
    "        for i in range(len(I)):\n",
    "            # bỏ chính nó\n",
    "            neighbors = I[i][I[i] != i][:K]\n",
    "            if labels_np[i] in labels_np[neighbors]:\n",
    "                correct += 1\n",
    "\n",
    "        recalls[K] = correct / len(I)\n",
    "\n",
    "    return recalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12829ac7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T17:08:49.743959Z",
     "iopub.status.busy": "2026-01-25T17:08:49.743728Z",
     "iopub.status.idle": "2026-01-25T17:08:54.752387Z",
     "shell.execute_reply": "2026-01-25T17:08:54.751499Z"
    },
    "papermill": {
     "duration": 5.014081,
     "end_time": "2026-01-25T17:08:54.754374",
     "exception": false,
     "start_time": "2026-01-25T17:08:49.740293",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23/3229847284.py:17: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler(enabled=use_amp)\n"
     ]
    }
   ],
   "source": [
    "model = VSL_BiLSTM_Encoder(\n",
    "    input_dim=201,\n",
    "    hidden_dim=256,\n",
    "    num_layers=2,\n",
    "    emb_dim=256\n",
    ")\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = SupConLoss(temperature=0.07)\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(), lr=1e-3, weight_decay=1e-4\n",
    ")\n",
    "\n",
    "use_amp = (device == \"cuda\")\n",
    "scaler = GradScaler(enabled=use_amp)\n",
    "\n",
    "epochs = 5\n",
    "eval_interval = 1\n",
    "\n",
    "save_dir = \"./checkpoints\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "best_recall1 = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee9064a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T17:08:54.763126Z",
     "iopub.status.busy": "2026-01-25T17:08:54.762586Z",
     "iopub.status.idle": "2026-01-25T17:16:49.138713Z",
     "shell.execute_reply": "2026-01-25T17:16:49.137761Z"
    },
    "papermill": {
     "duration": 474.382179,
     "end_time": "2026-01-25T17:16:49.140242",
     "exception": false,
     "start_time": "2026-01-25T17:08:54.758063",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:   0%|                                                                               | 0/1000 [00:00<?, ?it/s]/tmp/ipykernel_23/883657663.py:46: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=use_amp):\n",
      "Epoch 1/5: 100%|█████████████████████████████████████████████| 1000/1000 [02:47<00:00,  5.97it/s, loss=1.5410, lr=0.001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: train_loss=1.7374, lr=1.00e-03, time=167.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Valid Epoch 1 | R@1: 99.56% | \n",
      "Saved BEST encoder (Recall@1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|█████████████████████████████████████████████| 1000/1000 [01:17<00:00, 12.98it/s, loss=1.3025, lr=0.001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2: train_loss=1.4436, lr=1.00e-03, time=77.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Valid Epoch 2 | R@1: 99.74% | \n",
      "Saved BEST encoder (Recall@1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|█████████████████████████████████████████████| 1000/1000 [01:01<00:00, 16.27it/s, loss=1.3916, lr=0.001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3: train_loss=1.3414, lr=1.00e-03, time=61.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Valid Epoch 3 | R@1: 99.74% | \n",
      "Saved BEST encoder (Recall@1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|█████████████████████████████████████████████| 1000/1000 [00:55<00:00, 18.15it/s, loss=1.1305, lr=0.001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4: train_loss=1.2561, lr=1.00e-03, time=55.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Valid Epoch 4 | R@1: 99.84% | \n",
      "Saved BEST encoder (Recall@1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|█████████████████████████████████████████████| 1000/1000 [00:52<00:00, 19.22it/s, loss=1.1328, lr=0.001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5: train_loss=1.2001, lr=1.00e-03, time=52.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Valid Epoch 5 | R@1: 99.89% | \n",
      "Saved BEST encoder (Recall@1)\n",
      "Encoder training finished\n"
     ]
    }
   ],
   "source": [
    "lr_patience = 2\n",
    "early_stop_patience = 6\n",
    "best_recall1 = 0.0\n",
    "no_improve_count = 0\n",
    "\n",
    "log_path = os.path.join(save_dir, \"train_log.csv\")\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode=\"max\",\n",
    "    factor=0.3,\n",
    "    patience=lr_patience,\n",
    "    min_lr=1e-6,\n",
    ")\n",
    "\n",
    "\n",
    "if not os.path.exists(log_path):\n",
    "    with open(log_path, \"w\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\n",
    "            \"epoch\",\n",
    "            \"train_loss\",\n",
    "            \"recall@1\",\n",
    "            \"lr\",\n",
    "            \"epoch_time_sec\"\n",
    "        ])\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    start_time = time.time()\n",
    "\n",
    "    pbar = tqdm(\n",
    "        train_loader,\n",
    "        desc=f\"Epoch {epoch+1}/{epochs}\",\n",
    "        ncols=120\n",
    "    )\n",
    "\n",
    "    for step, (x, y) in enumerate(pbar):\n",
    "        x = x.to(device).float()\n",
    "        y = y.to(device).long()\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        with autocast(enabled=use_amp):\n",
    "            emb = model(x)\n",
    "            loss = criterion(emb, y)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        pbar.set_postfix({\n",
    "            \"loss\": f\"{loss.item():.4f}\",\n",
    "            \"lr\": optimizer.param_groups[0][\"lr\"]\n",
    "        })\n",
    "\n",
    "    avg_loss = epoch_loss / (step + 1)\n",
    "    epoch_time = time.time() - start_time\n",
    "    current_lr = optimizer.param_groups[0][\"lr\"]\n",
    "\n",
    "    print(\n",
    "        f\"\\nEpoch {epoch+1}: \"\n",
    "        f\"train_loss={avg_loss:.4f}, \"\n",
    "        f\"lr={current_lr:.2e}, \"\n",
    "        f\"time={epoch_time:.1f}s\"\n",
    "    )\n",
    "\n",
    "    # -------- SAVE LAST --------\n",
    "    torch.save(\n",
    "        {\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"model\": model.state_dict(),\n",
    "            \"optimizer\": optimizer.state_dict(),\n",
    "        },\n",
    "        f\"{save_dir}/last_encoder.pt\"\n",
    "    )\n",
    "\n",
    "    recall1 = None\n",
    "\n",
    "    if (epoch + 1) % eval_interval == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            recalls = eval_recall_at_k_faiss(\n",
    "                model,\n",
    "                val_loader,\n",
    "                device,\n",
    "                Ks=(1, 5)\n",
    "            )\n",
    "\n",
    "        recall1 = recalls[1]\n",
    "\n",
    "        print(\n",
    "            f\"\\n Valid Epoch {epoch+1} | \"\n",
    "            f\"R@1: {recall1*100:.2f}% | \"\n",
    "        )\n",
    "\n",
    "        scheduler.step(recall1)\n",
    "\n",
    "        if recall1 > best_recall1:\n",
    "            best_recall1 = recall1\n",
    "            no_improve_count = 0\n",
    "\n",
    "            torch.save(\n",
    "                model.state_dict(),\n",
    "                f\"{save_dir}/best_encoder.pt\"\n",
    "            )\n",
    "            print(\"Saved BEST encoder (Recall@1)\")\n",
    "\n",
    "        else:\n",
    "            no_improve_count += 1\n",
    "            print(\n",
    "                f\"⏸ No Recall@1 improvement \"\n",
    "                f\"({no_improve_count}/{early_stop_patience})\"\n",
    "            )\n",
    "\n",
    "    with open(log_path, \"a\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\n",
    "            epoch + 1,\n",
    "            round(avg_loss, 6),\n",
    "            None if recall1 is None else round(recall1, 6),\n",
    "            f\"{current_lr:.2e}\",\n",
    "            round(epoch_time, 2)\n",
    "        ])\n",
    "\n",
    "    if no_improve_count >= early_stop_patience:\n",
    "        print(\n",
    "            f\"\\nEarly stopping at epoch {epoch+1} \"\n",
    "            f\"(no Recall@1 improvement for \"\n",
    "            f\"{early_stop_patience} evals)\"\n",
    "        )\n",
    "        break\n",
    "\n",
    "print(\"Encoder training finished\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3eabaeb9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T17:16:49.668444Z",
     "iopub.status.busy": "2026-01-25T17:16:49.667645Z",
     "iopub.status.idle": "2026-01-25T17:16:58.188609Z",
     "shell.execute_reply": "2026-01-25T17:16:58.187661Z"
    },
    "papermill": {
     "duration": 8.786435,
     "end_time": "2026-01-25T17:16:58.190397",
     "exception": false,
     "start_time": "2026-01-25T17:16:49.403962",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Valid | R@1: 99.89% | R@5: 99.93%\n"
     ]
    }
   ],
   "source": [
    "model_dir = \"./checkpoints\"\n",
    "\n",
    "model = VSL_BiLSTM_Encoder(\n",
    "    input_dim=201,\n",
    "    hidden_dim=256,\n",
    "    num_layers=2,\n",
    "    emb_dim=256\n",
    ")\n",
    "\n",
    "model.to(\"cuda\")\n",
    "\n",
    "ckpt_path = f\"{model_dir}/best_encoder.pt\"\n",
    "model.load_state_dict(torch.load(ckpt_path, map_location=device))\n",
    "\n",
    "recalls = eval_recall_at_k_faiss(\n",
    "            model,\n",
    "            test_loader,\n",
    "            device,\n",
    "            Ks=(1, 5)\n",
    "        )\n",
    "\n",
    "recall1 = recalls[1]\n",
    "recall5 = recalls[5]\n",
    "\n",
    "print(\n",
    "    f\"\\n Valid | \"\n",
    "    f\"R@1: {recall1*100:.2f}% | \"\n",
    "    f\"R@5: {recall5*100:.2f}%\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ef88859",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T17:16:58.800008Z",
     "iopub.status.busy": "2026-01-25T17:16:58.799652Z",
     "iopub.status.idle": "2026-01-25T17:16:59.497880Z",
     "shell.execute_reply": "2026-01-25T17:16:59.496966Z"
    },
    "papermill": {
     "duration": 0.966716,
     "end_time": "2026-01-25T17:16:59.499634",
     "exception": false,
     "start_time": "2026-01-25T17:16:58.532918",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: checkpoints/best_encoder.pt (deflated 7%)\r\n"
     ]
    }
   ],
   "source": [
    "!zip best.zip ./checkpoints/best_encoder.pt"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 9273717,
     "sourceId": 14603584,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31260,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 585.404586,
   "end_time": "2026-01-25T17:17:02.478898",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-01-25T17:07:17.074312",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
