{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.12"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":14603584,"sourceType":"datasetVersion","datasetId":9273717}],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%pip install -q faiss-cpu mediapipe==0.10.14","metadata":{"execution":{"iopub.status.busy":"2026-01-25T13:55:46.078015Z","iopub.execute_input":"2026-01-25T13:55:46.078279Z","iopub.status.idle":"2026-01-25T13:55:54.251662Z","shell.execute_reply.started":"2026-01-25T13:55:46.078245Z","shell.execute_reply":"2026-01-25T13:55:54.250848Z"},"trusted":true},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.7/35.7 MB\u001b[0m \u001b[31m53.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.8/23.8 MB\u001b[0m \u001b[31m91.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngoogle-adk 1.22.1 requires google-cloud-bigquery-storage>=2.0.0, which is not installed.\nbigframes 2.26.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\na2a-sdk 0.3.22 requires protobuf>=5.29.5, but you have protobuf 4.25.8 which is incompatible.\nopentelemetry-proto 1.37.0 requires protobuf<7.0,>=5.0, but you have protobuf 4.25.8 which is incompatible.\nydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 4.25.8 which is incompatible.\nbigframes 2.26.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\ngrpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.8 which is incompatible.\ngcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.10.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\", category=RuntimeWarning)","metadata":{"execution":{"iopub.status.busy":"2026-01-25T13:56:06.827149Z","iopub.execute_input":"2026-01-25T13:56:06.827668Z","iopub.status.idle":"2026-01-25T13:56:06.831817Z","shell.execute_reply.started":"2026-01-25T13:56:06.827606Z","shell.execute_reply":"2026-01-25T13:56:06.830926Z"},"trusted":true},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import os\nimport numpy as np\nimport random\nimport json\nfrom torch.utils.data import Dataset, Sampler\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.cuda.amp import GradScaler, autocast\nfrom tqdm import tqdm\nimport time\nimport faiss\nimport csv\nimport mediapipe as mp","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2026-01-25T13:56:09.212027Z","iopub.execute_input":"2026-01-25T13:56:09.212344Z","iopub.status.idle":"2026-01-25T13:56:27.489291Z","shell.execute_reply.started":"2026-01-25T13:56:09.212320Z","shell.execute_reply":"2026-01-25T13:56:27.488695Z"},"trusted":true},"outputs":[{"name":"stderr","text":"2026-01-25 13:56:15.155732: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1769349375.360212      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1769349375.422121      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1769349375.918334      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1769349375.918369      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1769349375.918372      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1769349375.918375      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"class VSLDataset(Dataset):\n    def __init__(self, root_dir, label_map_path):\n        self.samples = []\n        self.labels = []\n        self.gloss_to_indices = {}\n\n        with open(label_map_path, \"r\", encoding=\"utf-8\") as f:\n            self.label_map = json.load(f)\n\n        for gloss_name in sorted(os.listdir(root_dir)):\n            gloss_path = os.path.join(root_dir, gloss_name)\n            if not os.path.isdir(gloss_path):\n                continue\n\n            if gloss_name not in self.label_map:\n                raise ValueError(f\"Gloss '{gloss_name}' not found in label_map.json\")\n\n            gloss_id = int(self.label_map[gloss_name])\n\n            for fname in os.listdir(gloss_path):\n                if not fname.endswith(\".npz\"):\n                    continue\n\n                fpath = os.path.join(gloss_path, fname)\n                idx = len(self.samples)\n\n                self.samples.append(fpath)\n                self.labels.append(gloss_id)\n\n                if gloss_id not in self.gloss_to_indices:\n                    self.gloss_to_indices[gloss_id] = []\n                self.gloss_to_indices[gloss_id].append(idx)\n\n    def __len__(self):\n        return len(self.samples)\n\n    def __getitem__(self, idx):\n        npz = np.load(self.samples[idx])\n        x = npz[\"sequence\"]\n        y = self.labels[idx]\n        return x, y","metadata":{"execution":{"iopub.status.busy":"2026-01-25T13:56:32.513346Z","iopub.execute_input":"2026-01-25T13:56:32.513661Z","iopub.status.idle":"2026-01-25T13:56:32.520940Z","shell.execute_reply.started":"2026-01-25T13:56:32.513609Z","shell.execute_reply":"2026-01-25T13:56:32.520341Z"},"trusted":true},"outputs":[],"execution_count":5},{"cell_type":"code","source":"class PKSampler(Sampler):\n    def __init__(self, gloss_to_indices, P=32, K=8, steps_per_epoch=1000):\n        self.gloss_to_indices = gloss_to_indices\n        self.P = P\n        self.K = K\n        self.steps_per_epoch = steps_per_epoch\n\n        self.ptr = {}\n        self.buffers = {}\n\n        # Chỉ giữ gloss đủ K sample\n        self.gloss_ids = [\n            g for g, idxs in gloss_to_indices.items()\n            if len(idxs) >= K\n        ]\n\n        if len(self.gloss_ids) < P:\n            raise ValueError(\n                f\"Not enough glosses with >=K samples: \"\n                f\"{len(self.gloss_ids)} < P={P}\"\n            )\n\n        for g in self.gloss_ids:\n            idxs = gloss_to_indices[g].copy()\n            random.shuffle(idxs)\n            self.buffers[g] = idxs\n            self.ptr[g] = 0\n\n    def __len__(self):\n        # pseudo-length (steps per epoch)\n        return self.steps_per_epoch\n\n    def __iter__(self):\n        for _ in range(self.steps_per_epoch):\n            batch = []\n\n            gloss_batch = random.sample(self.gloss_ids, self.P)\n\n            for g in gloss_batch:\n                idxs = self.buffers[g]\n                p = self.ptr[g]\n\n                if p + self.K > len(idxs):\n                    random.shuffle(idxs)\n                    p = 0\n\n                batch.extend(idxs[p:p + self.K])\n                self.ptr[g] = p + self.K\n\n            yield batch","metadata":{"execution":{"iopub.status.busy":"2026-01-25T13:56:34.879830Z","iopub.execute_input":"2026-01-25T13:56:34.880512Z","iopub.status.idle":"2026-01-25T13:56:34.890591Z","shell.execute_reply.started":"2026-01-25T13:56:34.880472Z","shell.execute_reply":"2026-01-25T13:56:34.889811Z"},"trusted":true},"outputs":[],"execution_count":6},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\nlabel_map_path = \"/kaggle/input/vsl-vietnamese-sign-languages/Processed/label_map.json\"\ntrain_root = \"/kaggle/input/vsl-vietnamese-sign-languages/Processed/train\"\nval_root = \"/kaggle/input/vsl-vietnamese-sign-languages/Processed/val\"\ntest_root = \"/kaggle/input/vsl-vietnamese-sign-languages/Processed/test\"\n\ntrain_ds = VSLDataset(train_root, label_map_path)\nval_ds = VSLDataset(val_root, label_map_path)\ntest_ds = VSLDataset(test_root, label_map_path)\n\nsampler = PKSampler(\n    gloss_to_indices=train_ds.gloss_to_indices,\n    P=32, # Số gloss mỗi step\n    K=4, # Số sequence mỗi step\n    steps_per_epoch=1000 # Số step mỗi epoch\n)\n\ntrain_loader = DataLoader(\n    train_ds,\n    batch_sampler=sampler,\n    num_workers=4,\n    pin_memory=True\n)\n\nval_loader = DataLoader(\n    val_ds,\n    batch_size=256,\n    num_workers=4,\n    pin_memory=True \n)\n\ntest_loader = DataLoader(\n    val_ds,\n    batch_size=256,\n    num_workers=4,\n    pin_memory=True \n)","metadata":{"execution":{"iopub.status.busy":"2026-01-25T13:56:48.527514Z","iopub.execute_input":"2026-01-25T13:56:48.528383Z","iopub.status.idle":"2026-01-25T13:57:52.727102Z","shell.execute_reply.started":"2026-01-25T13:56:48.528352Z","shell.execute_reply":"2026-01-25T13:57:52.726498Z"},"trusted":true},"outputs":[],"execution_count":8},{"cell_type":"code","source":"mp_holistic = mp.solutions.holistic\n\nN_UPPER_BODY_POSE_LANDMARKS = 25\nN_HAND_LANDMARKS = 21\nN_TOTAL_LANDMARKS = 67\n\n\ndef build_adjacency(self_loop=True):\n    A = torch.zeros(N_TOTAL_LANDMARKS, N_TOTAL_LANDMARKS)\n    for i, j in mp_holistic.POSE_CONNECTIONS:\n        if i < N_UPPER_BODY_POSE_LANDMARKS and j < N_UPPER_BODY_POSE_LANDMARKS:\n            A[i, j] = 1\n            A[j, i] = 1\n\n    LEFT_HAND_OFFSET = N_UPPER_BODY_POSE_LANDMARKS\n    for i, j in mp_holistic.HAND_CONNECTIONS:\n        A[LEFT_HAND_OFFSET + i, LEFT_HAND_OFFSET + j] = 1\n        A[LEFT_HAND_OFFSET + j, LEFT_HAND_OFFSET + i] = 1\n\n    RIGHT_HAND_OFFSET = N_UPPER_BODY_POSE_LANDMARKS + N_HAND_LANDMARKS\n    for i, j in mp_holistic.HAND_CONNECTIONS:\n        A[RIGHT_HAND_OFFSET + i, RIGHT_HAND_OFFSET + j] = 1\n        A[RIGHT_HAND_OFFSET + j, RIGHT_HAND_OFFSET + i] = 1\n\n    POSE_LEFT_WRIST = 15\n    POSE_RIGHT_WRIST = 16\n\n    LEFT_HAND_WRIST = LEFT_HAND_OFFSET + 0\n    RIGHT_HAND_WRIST = RIGHT_HAND_OFFSET + 0\n\n    A[POSE_LEFT_WRIST, LEFT_HAND_WRIST] = 1\n    A[LEFT_HAND_WRIST, POSE_LEFT_WRIST] = 1\n\n    A[POSE_RIGHT_WRIST, RIGHT_HAND_WRIST] = 1\n    A[RIGHT_HAND_WRIST, POSE_RIGHT_WRIST] = 1\n\n    if self_loop:\n        A += torch.eye(N_TOTAL_LANDMARKS)\n\n    A = A / A.sum(dim=1, keepdim=True)\n\n    return A\n\n\nclass STGCNBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, A, kernel_size=9, stride=1):\n        super().__init__()\n        self.register_buffer(\"A\", A)\n\n        # Spatial GCN\n        self.gcn = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n\n        # Temporal convolution\n        padding = ((kernel_size - 1) // 2, 0)\n        self.tcn = nn.Conv2d(\n            out_channels,\n            out_channels,\n            kernel_size=(kernel_size, 1),\n            stride=(stride, 1),\n            padding=padding\n        )\n\n        self.bn = nn.BatchNorm2d(out_channels)\n        self.relu = nn.ReLU(inplace=True)\n\n    def forward(self, x):\n        # x: (B, C, T, V)\n\n        # spatial graph conv\n        x = torch.einsum(\"vw,bctw->bctv\", self.A, x)\n        x = self.gcn(x)\n\n        # temporal conv\n        x = self.tcn(x)\n        x = self.bn(x)\n        x = self.relu(x)\n\n        return x\n\nclass VSL_STGCN(nn.Module):\n    def __init__(self, in_dim=3, hidden_dim=256, emb_dim=256):\n        super().__init__()\n\n        A = build_adjacency()\n\n        self.data_bn = nn.BatchNorm1d(N_TOTAL_LANDMARKS * in_dim)\n\n        self.stgcn1 = STGCNBlock(in_dim, hidden_dim, A)\n        self.stgcn2 = STGCNBlock(hidden_dim, hidden_dim, A)\n\n        self.fc = nn.Linear(hidden_dim, emb_dim)\n\n    def forward(self, x):\n        \"\"\"\n        x: (B, T, V*C)\n        \"\"\"\n        B, T, _ = x.shape\n        x = x.view(B, T, N_TOTAL_LANDMARKS, 3)\n        x = x.permute(0, 3, 1, 2)  # (B, C, T, V)\n\n        x = self.stgcn1(x)\n        x = self.stgcn2(x)\n\n        # global pooling\n        x = x.mean(dim=[2, 3])    # (B, hidden_dim)\n\n        emb = self.fc(x)\n        emb = F.normalize(emb, dim=1)\n        return emb","metadata":{"execution":{"iopub.status.busy":"2026-01-25T14:04:45.507302Z","iopub.execute_input":"2026-01-25T14:04:45.508031Z","iopub.status.idle":"2026-01-25T14:04:45.518895Z","shell.execute_reply.started":"2026-01-25T14:04:45.507992Z","shell.execute_reply":"2026-01-25T14:04:45.518177Z"},"trusted":true},"outputs":[],"execution_count":10},{"cell_type":"code","source":"class SupConLoss(nn.Module):\n    def __init__(self, temperature=0.07):\n        super().__init__()\n        self.temperature = temperature\n\n    def forward(self, features, labels):\n        features = F.normalize(features, dim=1)\n        labels = labels.view(-1, 1)\n\n        mask = torch.eq(labels, labels.T).float().to(features.device)\n\n        logits = torch.matmul(features, features.T) / self.temperature\n        logits = logits - logits.max(dim=1, keepdim=True)[0].detach()\n\n        logits_mask = torch.ones_like(mask)\n        logits_mask.fill_diagonal_(0)\n        mask = mask * logits_mask\n\n        exp_logits = torch.exp(logits) * logits_mask\n        log_prob = logits - torch.log(exp_logits.sum(1, keepdim=True) + 1e-8)\n\n        mean_log_prob_pos = (mask * log_prob).sum(1) / (mask.sum(1) + 1e-8)\n        loss = -mean_log_prob_pos.mean()\n        return loss","metadata":{"execution":{"iopub.status.busy":"2026-01-25T14:04:48.622723Z","iopub.execute_input":"2026-01-25T14:04:48.623291Z","iopub.status.idle":"2026-01-25T14:04:48.628935Z","shell.execute_reply.started":"2026-01-25T14:04:48.623249Z","shell.execute_reply":"2026-01-25T14:04:48.628085Z"},"trusted":true},"outputs":[],"execution_count":11},{"cell_type":"code","source":"def eval_recall_at_k_faiss(\n    model,\n    val_loader,\n    device,\n    Ks=(1, 5)\n):\n    model.eval()\n\n    # ===== 1. Extract embeddings =====\n    all_embs = []\n    all_labels = []\n\n    with torch.no_grad():\n        for x, y in tqdm(val_loader, desc=\"Extract val emb\", leave=False):\n            x = x.to(device).float()\n            emb = model(x)                 # (B, D)\n            emb = F.normalize(emb, dim=1)  # cosine\n\n            all_embs.append(emb.cpu())\n            all_labels.append(y.cpu())\n\n    all_embs = torch.cat(all_embs, dim=0)      # (N, D)\n    all_labels = torch.cat(all_labels, dim=0)  # (N,)\n\n    # ===== 2. FAISS index =====\n    emb_np = all_embs.numpy().astype(\"float32\")\n    labels_np = all_labels.numpy()\n\n    dim = emb_np.shape[1]\n\n    index = faiss.IndexFlatIP(dim)  # Inner Product\n    index.add(emb_np)               # N vectors\n\n    # ===== 3. Search =====\n    max_k = max(Ks) + 1  # +1 để bỏ self-match\n    D, I = index.search(emb_np, max_k)\n\n    recalls = {}\n    for K in Ks:\n        correct = 0\n        for i in range(len(I)):\n            # bỏ chính nó\n            neighbors = I[i][I[i] != i][:K]\n            if labels_np[i] in labels_np[neighbors]:\n                correct += 1\n\n        recalls[K] = correct / len(I)\n\n    return recalls","metadata":{"execution":{"iopub.status.busy":"2026-01-25T14:04:53.684028Z","iopub.execute_input":"2026-01-25T14:04:53.684319Z","iopub.status.idle":"2026-01-25T14:04:53.691350Z","shell.execute_reply.started":"2026-01-25T14:04:53.684294Z","shell.execute_reply":"2026-01-25T14:04:53.690689Z"},"trusted":true},"outputs":[],"execution_count":14},{"cell_type":"code","source":"model = VSL_STGCN(\n    in_dim=3,\n    hidden_dim=256,\n    emb_dim=256\n)\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nmodel = model.to(device)\n\ncriterion = SupConLoss(temperature=0.07)\noptimizer = torch.optim.AdamW(\n    model.parameters(), lr=1e-3, weight_decay=1e-4\n)\n\nuse_amp = (device == \"cuda\")\nscaler = GradScaler(enabled=use_amp)\n\nepochs = 5\neval_interval = 1\n\nsave_dir = \"./checkpoints\"\nos.makedirs(save_dir, exist_ok=True)\n\nbest_recall1 = 0.0","metadata":{"execution":{"iopub.status.busy":"2026-01-25T14:05:27.944850Z","iopub.execute_input":"2026-01-25T14:05:27.945135Z","iopub.status.idle":"2026-01-25T14:05:31.041337Z","shell.execute_reply.started":"2026-01-25T14:05:27.945112Z","shell.execute_reply":"2026-01-25T14:05:31.040664Z"},"trusted":true},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_55/3801874886.py:16: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = GradScaler(enabled=use_amp)\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"lr_patience = 2\nearly_stop_patience = 6\nbest_recall1 = 0.0\nno_improve_count = 0\n\nlog_path = os.path.join(save_dir, \"train_log.csv\")\n\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n    optimizer,\n    mode=\"max\",\n    factor=0.3,\n    patience=lr_patience,\n    min_lr=1e-6,\n)\n\n\nif not os.path.exists(log_path):\n    with open(log_path, \"w\", newline=\"\") as f:\n        writer = csv.writer(f)\n        writer.writerow([\n            \"epoch\",\n            \"train_loss\",\n            \"recall@1\",\n            \"lr\",\n            \"epoch_time_sec\"\n        ])\n\n\nfor epoch in range(epochs):\n    model.train()\n    epoch_loss = 0.0\n    start_time = time.time()\n\n    pbar = tqdm(\n        train_loader,\n        desc=f\"Epoch {epoch+1}/{epochs}\",\n        ncols=120\n    )\n\n    for step, (x, y) in enumerate(pbar):\n        x = x.to(device).float()\n        y = y.to(device).long()\n\n        optimizer.zero_grad(set_to_none=True)\n\n        with autocast(enabled=use_amp):\n            emb = model(x)\n            loss = criterion(emb, y)\n\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n\n        epoch_loss += loss.item()\n\n        pbar.set_postfix({\n            \"loss\": f\"{loss.item():.4f}\",\n            \"lr\": optimizer.param_groups[0][\"lr\"]\n        })\n\n    avg_loss = epoch_loss / (step + 1)\n    epoch_time = time.time() - start_time\n    current_lr = optimizer.param_groups[0][\"lr\"]\n\n    print(\n        f\"\\nEpoch {epoch+1}: \"\n        f\"train_loss={avg_loss:.4f}, \"\n        f\"lr={current_lr:.2e}, \"\n        f\"time={epoch_time:.1f}s\"\n    )\n\n    # -------- SAVE LAST --------\n    torch.save(\n        {\n            \"epoch\": epoch + 1,\n            \"model\": model.state_dict(),\n            \"optimizer\": optimizer.state_dict(),\n        },\n        f\"{save_dir}/last_encoder.pt\"\n    )\n\n    recall1 = None\n\n    if (epoch + 1) % eval_interval == 0:\n        model.eval()\n        with torch.no_grad():\n            recalls = eval_recall_at_k_faiss(\n                model,\n                val_loader,\n                device,\n                Ks=(1, 5)\n            )\n\n        recall1 = recalls[1]\n\n        print(\n            f\"\\n Valid Epoch {epoch+1} | \"\n            f\"R@1: {recall1*100:.2f}% | \"\n        )\n\n        scheduler.step(recall1)\n\n        if recall1 > best_recall1:\n            best_recall1 = recall1\n            no_improve_count = 0\n\n            torch.save(\n                model.state_dict(),\n                f\"{save_dir}/best_encoder.pt\"\n            )\n            print(\"Saved BEST encoder (Recall@1)\")\n\n        else:\n            no_improve_count += 1\n            print(\n                f\"⏸ No Recall@1 improvement \"\n                f\"({no_improve_count}/{early_stop_patience})\"\n            )\n\n    with open(log_path, \"a\", newline=\"\") as f:\n        writer = csv.writer(f)\n        writer.writerow([\n            epoch + 1,\n            round(avg_loss, 6),\n            None if recall1 is None else round(recall1, 6),\n            f\"{current_lr:.2e}\",\n            round(epoch_time, 2)\n        ])\n\n    if no_improve_count >= early_stop_patience:\n        print(\n            f\"\\nEarly stopping at epoch {epoch+1} \"\n            f\"(no Recall@1 improvement for \"\n            f\"{early_stop_patience} evals)\"\n        )\n        break\n\nprint(\"Encoder training finished\")\n","metadata":{"execution":{"iopub.status.busy":"2026-01-25T14:05:37.305626Z","iopub.execute_input":"2026-01-25T14:05:37.306177Z","iopub.status.idle":"2026-01-25T15:06:27.515596Z","shell.execute_reply.started":"2026-01-25T14:05:37.306147Z","shell.execute_reply":"2026-01-25T15:06:27.514702Z"},"trusted":true},"outputs":[{"name":"stderr","text":"Epoch 1/5:   0%|                                                                               | 0/1000 [00:00<?, ?it/s]/tmp/ipykernel_55/883657663.py:46: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast(enabled=use_amp):\nEpoch 1/5: 100%|█████████████████████████████████████████████| 1000/1000 [11:40<00:00,  1.43it/s, loss=1.7058, lr=0.001]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: train_loss=1.8482, lr=1.00e-03, time=700.3s\n","output_type":"stream"},{"name":"stderr","text":"                                                                \r","output_type":"stream"},{"name":"stdout","text":"\n Valid Epoch 1 | R@1: 96.88% | \nSaved BEST encoder (Recall@1)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/5: 100%|█████████████████████████████████████████████| 1000/1000 [11:38<00:00,  1.43it/s, loss=1.5281, lr=0.001]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 2: train_loss=1.6287, lr=1.00e-03, time=698.7s\n","output_type":"stream"},{"name":"stderr","text":"                                                                \r","output_type":"stream"},{"name":"stdout","text":"\n Valid Epoch 2 | R@1: 98.23% | \nSaved BEST encoder (Recall@1)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/5: 100%|█████████████████████████████████████████████| 1000/1000 [11:38<00:00,  1.43it/s, loss=1.9454, lr=0.001]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 3: train_loss=1.5509, lr=1.00e-03, time=698.6s\n","output_type":"stream"},{"name":"stderr","text":"                                                                \r","output_type":"stream"},{"name":"stdout","text":"\n Valid Epoch 3 | R@1: 99.16% | \nSaved BEST encoder (Recall@1)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/5: 100%|█████████████████████████████████████████████| 1000/1000 [11:38<00:00,  1.43it/s, loss=1.3279, lr=0.001]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 4: train_loss=1.5264, lr=1.00e-03, time=698.4s\n","output_type":"stream"},{"name":"stderr","text":"                                                                \r","output_type":"stream"},{"name":"stdout","text":"\n Valid Epoch 4 | R@1: 99.33% | \nSaved BEST encoder (Recall@1)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/5: 100%|█████████████████████████████████████████████| 1000/1000 [11:38<00:00,  1.43it/s, loss=1.5164, lr=0.001]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 5: train_loss=1.4960, lr=1.00e-03, time=698.4s\n","output_type":"stream"},{"name":"stderr","text":"                                                                \r","output_type":"stream"},{"name":"stdout","text":"\n Valid Epoch 5 | R@1: 99.30% | \n⏸ No Recall@1 improvement (1/6)\nEncoder training finished\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"model_dir = \"./checkpoints\"\n\nmodel = VSL_STGCN(\n    in_dim=3,\n    hidden_dim=256,\n    emb_dim=256\n)\n\nmodel.to(\"cuda\")\n\nckpt_path = f\"{model_dir}/best_encoder.pt\"\nmodel.load_state_dict(torch.load(ckpt_path, map_location=device))\n\nrecalls = eval_recall_at_k_faiss(\n            model,\n            test_loader,\n            device,\n            Ks=(1, 5)\n        )\n\nrecall1 = recalls[1]\nrecall5 = recalls[5]\n\nprint(\n    f\"\\n Valid | \"\n    f\"R@1: {recall1*100:.2f}% | \"\n    f\"R@5: {recall5*100:.2f}%\"\n)","metadata":{"execution":{"iopub.status.busy":"2026-01-25T15:12:55.348182Z","iopub.execute_input":"2026-01-25T15:12:55.348531Z","iopub.status.idle":"2026-01-25T15:13:24.940695Z","shell.execute_reply.started":"2026-01-25T15:12:55.348500Z","shell.execute_reply":"2026-01-25T15:13:24.939938Z"},"trusted":true},"outputs":[{"name":"stderr","text":"                                                                \r","output_type":"stream"},{"name":"stdout","text":"\n Valid | R@1: 99.33% | R@5: 99.76%\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"!zip best.zip ./checkpoints/best_encoder.pt","metadata":{"execution":{"iopub.status.busy":"2026-01-25T15:16:38.129993Z","iopub.execute_input":"2026-01-25T15:16:38.130346Z","iopub.status.idle":"2026-01-25T15:16:38.551343Z","shell.execute_reply.started":"2026-01-25T15:16:38.130314Z","shell.execute_reply":"2026-01-25T15:16:38.550577Z"},"trusted":true},"outputs":[{"name":"stdout","text":"  adding: checkpoints/best_encoder.pt (deflated 8%)\n","output_type":"stream"}],"execution_count":19}]}